{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Catboost Tuning\n",
    "## Summary\n",
    "In this notebook I will primarily tune some models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing Data and Required Packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from catboost import CatBoostClassifier, metrics, cv\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "import optuna\n",
    "\n",
    "from functions import metrics as custom_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Training Data\n",
    "X_train = pd.read_csv('../Data/train/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../Data/train/y_train.csv', index_col=0)\n",
    "\n",
    "# Testing Data\n",
    "X_test = pd.read_csv('../Data/test/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../Data/test/y_test.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Currently the classes are labelled as \"1\" as dignosed ADHD and \"2\" as not diagnosed, but models seem to dislike this.\n",
    "testing = {2: 0, 1: 1}\n",
    "labels = y_train.replace(testing)\n",
    "test_labels = y_test.replace(testing)\n",
    "\n",
    "# This cell will be moved into the \"Data cleaning\" notebook in the future."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Initiate Over sampler\n",
    "ros = RandomOverSampler(random_state=15)\n",
    "\n",
    "# Applying ONLY to training set to prevent data leakage.\n",
    "X_train_os, y_train_os = ros.fit_resample(X_train, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimizing with the Optuna\n",
    "For the hyperparameter tuning process, I'll be using the [Optuna](https://optuna.readthedocs.io/en/stable/index.html) library. I'll also be making use of Catboost's cross-validation in selecting the best model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Optuna requires us to define the \"objective function\". Which will be called upon each iteration during our \"trials\"\n",
    "def objective(trial):\n",
    "    # Dict of Parameters to check\n",
    "    param = {\n",
    "        # Metric used for model optimization\n",
    "        'loss_function':trial.suggest_categorical('loss_function', ['Logloss', 'CrossEntropy']),\n",
    "\n",
    "        # The maximum number of trees that can be built.\n",
    "        'iterations':trial.suggest_categorical('iterations', [100,200,300,500,1000]),\n",
    "\n",
    "        # learning rate for gradient descent calculations.\n",
    "        'learning_rate':trial.suggest_float(\"learning_rate\", 0.001, 0.3),\n",
    "\n",
    "        # Coefficient at the L2 regularization term of the cost function.\n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "\n",
    "        # Affects the speed and regularization of tree\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "\n",
    "        # The amount of randomness to use for scoring splits.\n",
    "        'random_strength':trial.suggest_int(\"random_strength\", 1,10),\n",
    "\n",
    "        # The number of splits for numerical features.\n",
    "        'max_bin':trial.suggest_categorical('max_bin', [4,5,6,8,10,20,30]),\n",
    "\n",
    "        # Allowed depth of tree.\n",
    "        \"depth\": trial.suggest_int(\"max_depth\", 2,16),\n",
    "\n",
    "        # Defines how to perform greedy tree construction.\n",
    "        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "\n",
    "        # The minimum number of training samples in a leaf.\n",
    "        'min_data_in_leaf':trial.suggest_int(\"min_data_in_leaf\", 1,10),\n",
    "\n",
    "        # Only OHE encodes features if the number of unique values will be <= the parameter vale.\n",
    "        'one_hot_max_size':trial.suggest_categorical('one_hot_max_size', [5,10,12,100]),\n",
    "    }\n",
    "\n",
    "    # Certain parameters are \"subparameters\" and can only be set if their parent parameter has a certain value.\n",
    "\n",
    "    # Bootstrap types\n",
    "    if param['bootstrap_type'] == \"Bayesian\":\n",
    "\n",
    "        # Use Baysesian bootstrapping to assign random weights to objects.\n",
    "        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 10)\n",
    "\n",
    "    elif param['bootstrap_type'] in ['Bernoulli', 'MVS']:\n",
    "        # Sample rate for bagging using Bernoulli/MVS type\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.1, 1)\n",
    "\n",
    "    # Grow policy params\n",
    "    if param['grow_policy'] != 'SymmetricTree':\n",
    "\n",
    "        # The minimum number of training samples in a leaf.\n",
    "        param['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 1, 10)\n",
    "\n",
    "        if param['grow_policy'] == 'LossGuide':\n",
    "\n",
    "            # The maximum number of leafs in the tree.\n",
    "            param['max_leaves'] = trial.suggest_int('max_leaves', 16, 64)\n",
    "\n",
    "\n",
    "    # Creates the trial model with parameters specified above.\n",
    "    trial_model = CatBoostClassifier(**param)\n",
    "\n",
    "    # Fit the training model on training data\n",
    "    trial_model.fit(X_train_os,\n",
    "                    y_train_os,\n",
    "                    eval_set=[(X_test, test_labels)],\n",
    "                    verbose=0, # Stops Catboost from printing training results.\n",
    "                    early_stopping_rounds=10 # Specify rounds of no improvement needed before stopping\n",
    "                    )\n",
    "\n",
    "    # Create predictions for test set\n",
    "    preds = trial_model.predict(X_test)\n",
    "\n",
    "    # Calculate recall score\n",
    "    accuracy = recall_score(test_labels, preds)\n",
    "\n",
    "    return recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-11-30 11:55:51,364]\u001B[0m A new study created in memory with name: no-name-ef0b8f1e-a2b5-4ec5-86f2-4edeb974c77d\u001B[0m\n",
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe.\u001B[32m[I 2021-11-30 11:55:57,030]\u001B[0m Trial 0 finished with value: 0.8403465346534653 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.2044338772487664, 'l2_leaf_reg': 22.500465873561627, 'bootstrap_type': 'Bernoulli', 'random_strength': 6, 'max_bin': 5, 'max_depth': 3, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'one_hot_max_size': 10, 'subsample': 0.32810303352785786}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:56:25,849]\u001B[0m Trial 1 finished with value: 0.8366336633663366 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.12708222211312362, 'l2_leaf_reg': 14.391674300428008, 'bootstrap_type': 'Bernoulli', 'random_strength': 10, 'max_bin': 6, 'max_depth': 7, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'subsample': 0.8065825311169242}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:57:14,699]\u001B[0m Trial 2 finished with value: 0.7215346534653465 and parameters: {'loss_function': 'Logloss', 'iterations': 300, 'learning_rate': 0.1403602331327999, 'l2_leaf_reg': 0.4196243986549289, 'bootstrap_type': 'Bernoulli', 'random_strength': 7, 'max_bin': 20, 'max_depth': 16, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 8, 'one_hot_max_size': 5, 'subsample': 0.470871027965132}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:57:23,448]\u001B[0m Trial 3 finished with value: 0.75 and parameters: {'loss_function': 'Logloss', 'iterations': 300, 'learning_rate': 0.16329315159075275, 'l2_leaf_reg': 1.498720503194167e-06, 'bootstrap_type': 'MVS', 'random_strength': 10, 'max_bin': 8, 'max_depth': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'one_hot_max_size': 10, 'subsample': 0.3764820506334645}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:57:41,045]\u001B[0m Trial 4 finished with value: 0.8366336633663366 and parameters: {'loss_function': 'Logloss', 'iterations': 300, 'learning_rate': 0.10826295130834077, 'l2_leaf_reg': 58.95401096663848, 'bootstrap_type': 'Bayesian', 'random_strength': 8, 'max_bin': 30, 'max_depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'one_hot_max_size': 10, 'bagging_temperature': 8.885697287114247}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:58:12,842]\u001B[0m Trial 5 finished with value: 0.6720297029702971 and parameters: {'loss_function': 'Logloss', 'iterations': 500, 'learning_rate': 0.16526333037158167, 'l2_leaf_reg': 0.06727172526418483, 'bootstrap_type': 'Bernoulli', 'random_strength': 1, 'max_bin': 10, 'max_depth': 7, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'one_hot_max_size': 100, 'subsample': 0.978842733483337}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:58:35,697]\u001B[0m Trial 6 finished with value: 0.8341584158415841 and parameters: {'loss_function': 'Logloss', 'iterations': 500, 'learning_rate': 0.06669752625165494, 'l2_leaf_reg': 9.326500800497853e-06, 'bootstrap_type': 'Bayesian', 'random_strength': 6, 'max_bin': 5, 'max_depth': 3, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 5, 'one_hot_max_size': 10, 'bagging_temperature': 3.7295134498143545}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:59:06,690]\u001B[0m Trial 7 finished with value: 0.8279702970297029 and parameters: {'loss_function': 'CrossEntropy', 'iterations': 500, 'learning_rate': 0.2562862483164053, 'l2_leaf_reg': 3.018082423188667e-08, 'bootstrap_type': 'Bayesian', 'random_strength': 4, 'max_bin': 6, 'max_depth': 3, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 8, 'one_hot_max_size': 100, 'bagging_temperature': 2.4322177386317834}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 11:59:23,173]\u001B[0m Trial 8 finished with value: 0.5581683168316832 and parameters: {'loss_function': 'CrossEntropy', 'iterations': 1000, 'learning_rate': 0.16588869094448294, 'l2_leaf_reg': 2.4788068570751052e-06, 'bootstrap_type': 'MVS', 'random_strength': 2, 'max_bin': 20, 'max_depth': 13, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'one_hot_max_size': 100, 'subsample': 0.2181254067570833}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:00:07,798]\u001B[0m Trial 9 finished with value: 0.7982673267326733 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.06340633932795268, 'l2_leaf_reg': 9.949795092138727, 'bootstrap_type': 'Bernoulli', 'random_strength': 7, 'max_bin': 10, 'max_depth': 12, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'one_hot_max_size': 10, 'subsample': 0.4667036278576726}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:00:19,746]\u001B[0m Trial 10 finished with value: 0.7202970297029703 and parameters: {'loss_function': 'CrossEntropy', 'iterations': 200, 'learning_rate': 0.26230346804135524, 'l2_leaf_reg': 0.001998041892572105, 'bootstrap_type': 'Bernoulli', 'random_strength': 4, 'max_bin': 5, 'max_depth': 6, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'one_hot_max_size': 12, 'subsample': 0.10628694042859832}. Best is trial 0 with value: 0.8403465346534653.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:00:42,234]\u001B[0m Trial 11 finished with value: 0.8465346534653465 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.0015389876145033288, 'l2_leaf_reg': 1.0693110404155657, 'bootstrap_type': 'Bernoulli', 'random_strength': 10, 'max_bin': 6, 'max_depth': 7, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'subsample': 0.8238981061897406}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:00:48,508]\u001B[0m Trial 12 finished with value: 0.8267326732673267 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.008186474770421441, 'l2_leaf_reg': 0.42527520648908074, 'bootstrap_type': 'Bernoulli', 'random_strength': 9, 'max_bin': 4, 'max_depth': 2, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 3, 'one_hot_max_size': 12, 'subsample': 0.675780114841188}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:01:07,574]\u001B[0m Trial 13 finished with value: 0.7561881188118812 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.21929361718099735, 'l2_leaf_reg': 0.00595051574667478, 'bootstrap_type': 'Bernoulli', 'random_strength': 4, 'max_bin': 5, 'max_depth': 6, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 3, 'one_hot_max_size': 5, 'subsample': 0.6842281485112691}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:02:06,071]\u001B[0m Trial 14 finished with value: 0.6658415841584159 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.21187859438931447, 'l2_leaf_reg': 1.6170554823460968, 'bootstrap_type': 'MVS', 'random_strength': 5, 'max_bin': 6, 'max_depth': 9, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'one_hot_max_size': 10, 'subsample': 0.986595441242605}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:02:12,768]\u001B[0m Trial 15 finished with value: 0.8032178217821783 and parameters: {'loss_function': 'CrossEntropy', 'iterations': 200, 'learning_rate': 0.2976695403499029, 'l2_leaf_reg': 94.02793371198806, 'bootstrap_type': 'Bernoulli', 'random_strength': 8, 'max_bin': 8, 'max_depth': 5, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'subsample': 0.31807918683486497}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:06:34,488]\u001B[0m Trial 16 finished with value: 0.8366336633663366 and parameters: {'loss_function': 'Logloss', 'iterations': 1000, 'learning_rate': 0.008018578635782751, 'l2_leaf_reg': 0.043947932299460916, 'bootstrap_type': 'Bernoulli', 'random_strength': 2, 'max_bin': 4, 'max_depth': 9, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'subsample': 0.8086585245752352}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:06:37,987]\u001B[0m Trial 17 finished with value: 0.8366336633663366 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.21309824919397694, 'l2_leaf_reg': 0.0001786460806528358, 'bootstrap_type': 'Bernoulli', 'random_strength': 6, 'max_bin': 30, 'max_depth': 2, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 6, 'one_hot_max_size': 12, 'subsample': 0.6373400761366531}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:06:59,215]\u001B[0m Trial 18 finished with value: 0.8341584158415841 and parameters: {'loss_function': 'CrossEntropy', 'iterations': 100, 'learning_rate': 0.058123165982134524, 'l2_leaf_reg': 1.6696212697323307, 'bootstrap_type': 'Bayesian', 'random_strength': 9, 'max_bin': 5, 'max_depth': 8, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 2, 'one_hot_max_size': 5, 'bagging_temperature': 0.05859115613655508}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:08:24,917]\u001B[0m Trial 19 finished with value: 0.6868811881188119 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.092516725388408, 'l2_leaf_reg': 9.028439884305035e-05, 'bootstrap_type': 'MVS', 'random_strength': 8, 'max_bin': 6, 'max_depth': 11, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'one_hot_max_size': 10, 'subsample': 0.8352395389525149}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:08:59,179]\u001B[0m Trial 20 finished with value: 0.724009900990099 and parameters: {'loss_function': 'Logloss', 'iterations': 200, 'learning_rate': 0.18989602593093885, 'l2_leaf_reg': 0.02601519972375468, 'bootstrap_type': 'Bernoulli', 'random_strength': 5, 'max_bin': 6, 'max_depth': 5, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 2, 'one_hot_max_size': 10, 'subsample': 0.5617753456377053}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:09:25,047]\u001B[0m Trial 21 finished with value: 0.8329207920792079 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.12381307781573965, 'l2_leaf_reg': 7.856268829081969, 'bootstrap_type': 'Bernoulli', 'random_strength': 10, 'max_bin': 6, 'max_depth': 7, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'subsample': 0.8057953160509863}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:09:48,030]\u001B[0m Trial 22 finished with value: 0.8366336633663366 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.036932494697253064, 'l2_leaf_reg': 17.215505342179874, 'bootstrap_type': 'Bernoulli', 'random_strength': 10, 'max_bin': 6, 'max_depth': 8, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'subsample': 0.8895260746680738}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:10:13,898]\u001B[0m Trial 23 finished with value: 0.8292079207920792 and parameters: {'loss_function': 'Logloss', 'iterations': 100, 'learning_rate': 0.019976847690233147, 'l2_leaf_reg': 0.6677283783193728, 'bootstrap_type': 'Bernoulli', 'random_strength': 9, 'max_bin': 6, 'max_depth': 14, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 4, 'one_hot_max_size': 10, 'subsample': 0.9081265351728082}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:10:31,245]\u001B[0m Trial 24 finished with value: 0.8378712871287128 and parameters: {'loss_function': 'Logloss', 'iterations': 300, 'learning_rate': 0.09865036338314263, 'l2_leaf_reg': 64.65843003194101, 'bootstrap_type': 'Bayesian', 'random_strength': 8, 'max_bin': 30, 'max_depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 9, 'one_hot_max_size': 10, 'bagging_temperature': 9.914928863261128}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:10:46,407]\u001B[0m Trial 25 finished with value: 0.8391089108910891 and parameters: {'loss_function': 'Logloss', 'iterations': 300, 'learning_rate': 0.09791709357174296, 'l2_leaf_reg': 3.2666548166554854, 'bootstrap_type': 'Bayesian', 'random_strength': 7, 'max_bin': 30, 'max_depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 10, 'one_hot_max_size': 10, 'bagging_temperature': 9.769376243721716}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n",
      "\u001B[32m[I 2021-11-30 12:11:04,956]\u001B[0m Trial 26 finished with value: 0.8329207920792079 and parameters: {'loss_function': 'Logloss', 'iterations': 300, 'learning_rate': 0.18811075835546273, 'l2_leaf_reg': 0.1927955894329751, 'bootstrap_type': 'Bayesian', 'random_strength': 7, 'max_bin': 30, 'max_depth': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 7, 'one_hot_max_size': 5, 'bagging_temperature': 6.742136093112308}. Best is trial 11 with value: 0.8465346534653465.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 27\n",
      "Best trial:\n",
      "  Value: 0.8465346534653465\n",
      "  Params: \n",
      "    loss_function: Logloss\n",
      "    iterations: 100\n",
      "    learning_rate: 0.0015389876145033288\n",
      "    l2_leaf_reg: 1.0693110404155657\n",
      "    bootstrap_type: Bernoulli\n",
      "    random_strength: 10\n",
      "    max_bin: 6\n",
      "    max_depth: 7\n",
      "    grow_policy: Lossguide\n",
      "    min_data_in_leaf: 1\n",
      "    one_hot_max_size: 10\n",
      "    subsample: 0.8238981061897406\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a \"trial\" object and specify we want to MAXIMIZE the value being returned by the obj function\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Running 100 trials, setting a timeout value of 15 minutes to prevent my computer from exploding.\n",
    "study.optimize(objective, n_trials=100, timeout=900)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "trial = study.best_trial\n",
    "\n",
    "# \"Prettify\" our trial results\n",
    "print(\"Best trial:\")\n",
    "\n",
    "# Print metric value achived from best trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "# Print all parameters from best trial\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x123683bb0>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model with the parameters from our best trial\n",
    "final_model = CatBoostClassifier(verbose=False, **trial.params)\n",
    "final_model.fit(X_train_os, y_train_os)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results\n",
      "Accuracy: 0.80\n",
      "Precision: 0.32\n",
      "Recall: 0.85\n",
      "F1: 0.47\n",
      "ROC AUC: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Show custom metrics\n",
    "final_results = custom_metric(test_labels, final_model.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}