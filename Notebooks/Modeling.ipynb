{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modeling Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this Notebook:\n",
    "- A first simple model is created\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "\n",
    "# Importing metrics function from functions.py\n",
    "from functions import metrics as custom_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in cleaned data from last time.\n",
    "\n",
    "# Training Data\n",
    "X_train = pd.read_csv('../Data/train/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../Data/train/y_train.csv', index_col=0)\n",
    "\n",
    "# Testing Data\n",
    "X_test = pd.read_csv('../Data/test/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../Data/test/y_test.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeless Baseline\n",
    "A modeless baseline is how accurate we would be if we guessed the majority class of our target variable. In this case, how accurate would we be if we guessed that the child in question did not have ADHD, for every child. This will be same for every split since we set the stratify parameter to true when we performed the TTS. It will be important to keep this metric in mind when modeling, to see when the model is just guessing the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we said that each child in the set did not have ADHD, we would be 90% accurate\n"
     ]
    }
   ],
   "source": [
    "# Getting % of each class and assigning to variables\n",
    "no_adhd, adhd = y_train.value_counts(normalize=True)\n",
    "\n",
    "# Printing modeless accuracy\n",
    "print(f'If we said that each child in the set did not have ADHD, we would be {no_adhd*100:.0f}% accurate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM - Sklearn Decision Tree\n",
    "\n",
    "To start let's create the simplest model possible, to use as a baseline for future models. I'll use a Decision Tree model from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating Tree\n",
    "FSM_DT = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting Model\n",
    "FSM_DT.fit(X_train, y_train)\n",
    "\n",
    "# Score on the training data.\n",
    "custom_score(y_train, FSM_DT.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wow! A perfect Score!\n",
    "I guess we can go home, we did it, we solved ADHD\n",
    "\n",
    "Just kidding, lets check the score on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "Precision: 0.49\n",
      "Recall: 0.54\n",
      "F1: 0.51\n",
      "ROC AUC: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "FSM_DT_preds = FSM_DT.predict(X_test)\n",
    "\n",
    "# Print metrics\n",
    "custom_score(y_test, FSM_DT_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    7104\n",
       "1.0     882\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the predictions to ensure that the model isn't guessing one class\n",
    "pd.Series(FSM_DT_preds).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis\n",
    "The model is, obviously, overfit to the training data, and on the testing data it may as well be guessing. This is expected of an un-pruned DT model though.\n",
    "I'd like to try a few different kinds of first models, so before iterating on this one let's create a few more FSMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FSM - CatBoost\n",
    "Catboost is not an Sklearn library, but is known for doing very well on categorical data like the one from this survey. Let's give it a shot and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "model = CatBoostClassifier(\n",
    "    # Adding Accuracy as a metric\n",
    "    custom_loss=[metrics.Accuracy()],\n",
    "    random_seed=15,\n",
    "    logging_level='Silent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35314d41cb441cfafbbb66d4e6abad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model to training data\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    # Using X/y test as eval set\n",
    "    eval_set=(X_test, y_test),\n",
    "    # Plot the learning of the model\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad650903874646c1a035b843fd04a6c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updating model params with Logloss function\n",
    "cv_params = model.get_params()\n",
    "cv_params.update({\n",
    "    'loss_function': metrics.Logloss()\n",
    "})\n",
    "# Pooling data and cross validating\n",
    "cv_data = cv(\n",
    "    Pool(X_train, y_train),\n",
    "    cv_params,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.97\n",
      "Precision: 0.93\n",
      "Recall: 0.73\n",
      "F1: 0.82\n",
      "ROC AUC: 0.86\n",
      "\t\n",
      "Testing Scores\n",
      "Accuracy: 0.94\n",
      "Precision: 0.74\n",
      "Recall: 0.56\n",
      "F1: 0.64\n",
      "ROC AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Printing training and testing scores.\n",
    "print(\"Training Scores\")\n",
    "custom_score(y_train, model.predict(X_train))\n",
    "print('\\t')\n",
    "print('Testing Scores')\n",
    "custom_score(y_test, model.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "Catboost has done quite well for a baseline model! There is, again, some bad overfitting occuring here. But the scores are still better then the base decision tree; precision, recall, and roc/auc have all vastly improved compared to the base decision tree. Lets move on to something totally different, a neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}