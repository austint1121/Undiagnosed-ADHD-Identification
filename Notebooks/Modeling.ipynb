{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modeling Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- In this Notebook I will be creating 3 simple models with:\n",
    "    - Sklearn's Base Decision Tree\n",
    "    - Catboost\n",
    "    - Keras\n",
    "\n",
    "I'll evaluate on all of these FSMs and decide how to move forward, and how to split my time between these model types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Importing metrics function from functions.py\n",
    "from functions import metrics as custom_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in cleaned data from last time.\n",
    "\n",
    "# Training Data\n",
    "X_train = pd.read_csv('../Data/train/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../Data/train/y_train.csv', index_col=0)\n",
    "\n",
    "# Testing Data\n",
    "X_test = pd.read_csv('../Data/test/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../Data/test/y_test.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeless Baseline\n",
    "A modeless baseline is how accurate we would be if we guessed the majority class of our target variable. In this case, how accurate would we be if we guessed that the child in question did not have ADHD, for every child. This will be same for every split since we set the stratify parameter to true when we performed the TTS. It will be important to keep this metric in mind when modeling, to see when the model is just guessing the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "K2Q31A\n2.0       0.898907\n1.0       0.101093\ndtype: float64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we said that each child in the set did not have ADHD, we would be 90% accurate\n"
     ]
    }
   ],
   "source": [
    "# Getting % of each class and assigning to variables\n",
    "no_adhd, adhd = y_train.value_counts(normalize=True)\n",
    "\n",
    "# Printing modeless accuracy\n",
    "print(f'If we said that each child in the set did not have ADHD, we would be {no_adhd*100:.0f}% accurate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM - Sklearn Decision Tree\n",
    "\n",
    "To start let's create the simplest model possible, to use as a baseline for future models. I'll use a Decision Tree model from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating Tree\n",
    "FSM_DT = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting Model\n",
    "FSM_DT.fit(X_train, y_train)\n",
    "\n",
    "# Score on the training data.\n",
    "custom_score(y_train, FSM_DT.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wow! A perfect Score!\n",
    "I guess we can go home, we did it, we solved ADHD\n",
    "\n",
    "Just kidding, lets check the score on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "Precision: 0.49\n",
      "Recall: 0.54\n",
      "F1: 0.51\n",
      "ROC AUC: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "FSM_DT_preds = FSM_DT.predict(X_test)\n",
    "\n",
    "# Print metrics\n",
    "custom_score(y_test, FSM_DT_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    7104\n",
       "1.0     882\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the predictions to ensure that the model isn't guessing one class\n",
    "pd.Series(FSM_DT_preds).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis\n",
    "The model is, obviously, overfit to the training data, and on the testing data it may as well be guessing. This is expected of an un-pruned DT model though.\n",
    "I'd like to try a few different kinds of first models, so before iterating on this one let's create a few more FSMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FSM - CatBoost\n",
    "Catboost is not an Sklearn library, but is known for doing very well on categorical data like the one from this survey. Let's give it a shot and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "model = CatBoostClassifier(\n",
    "    # Adding Accuracy as a metric\n",
    "    custom_loss=[metrics.Accuracy()],\n",
    "    random_seed=15,\n",
    "    logging_level='Silent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35314d41cb441cfafbbb66d4e6abad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model to training data\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    # Using X/y test as eval set\n",
    "    eval_set=(X_test, y_test),\n",
    "    # Plot the learning of the model\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad650903874646c1a035b843fd04a6c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updating model params with Logloss function\n",
    "cv_params = model.get_params()\n",
    "cv_params.update({\n",
    "    'loss_function': metrics.Logloss()\n",
    "})\n",
    "# Pooling data and cross validating\n",
    "cv_data = cv(\n",
    "    Pool(X_train, y_train),\n",
    "    cv_params,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.97\n",
      "Precision: 0.93\n",
      "Recall: 0.73\n",
      "F1: 0.82\n",
      "ROC AUC: 0.86\n",
      "\t\n",
      "Testing Scores\n",
      "Accuracy: 0.94\n",
      "Precision: 0.74\n",
      "Recall: 0.56\n",
      "F1: 0.64\n",
      "ROC AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Printing training and testing scores.\n",
    "print(\"Training Scores\")\n",
    "custom_score(y_train, model.predict(X_train))\n",
    "print('\\t')\n",
    "print('Testing Scores')\n",
    "custom_score(y_test, model.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "Catboost has done quite well for a baseline model! There is, again, some bad overfitting occuring here. But the scores are still better then the base decision tree; precision, recall, and roc/auc have all vastly improved compared to the base decision tree. Lets move on to something totally different, a neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FSM - Keras NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Currently the classes are labelled as \"1\" as dignosed ADHD and \"2\" as not diagnosed, but Keras seems to dislike this.\n",
    "lb = LabelBinarizer()\n",
    "# Using sklearn LabelBinarizer to change classes to \"0\" and \"1\" so that Keras doesn't get confused.\n",
    "labels = lb.fit_transform(y_train)\n",
    "test_labels = lb.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Instantiating a NN\n",
    "FSM_NN = keras.Sequential()\n",
    "\n",
    "# Starting small with 30 neurons\n",
    "FSM_NN.add(Dense(30, 'relu', input_shape=(422,)))\n",
    "\n",
    "# 1 output\n",
    "FSM_NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "# Compiling model with accuracy, precision, and recall metrics. Using \"Adam\" as an optimizer\n",
    "FSM_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 5.2351 - acc: 0.8992 - precision: 0.9440 - recall: 0.9438 - val_loss: 5.2315 - val_acc: 0.9154 - val_precision: 0.9282 - val_recall: 0.9817\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 4.6258 - acc: 0.8979 - precision: 0.9441 - recall: 0.9422 - val_loss: 44.9626 - val_acc: 0.8988 - val_precision: 0.8988 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 9.7854 - acc: 0.8925 - precision: 0.9389 - recall: 0.9418 - val_loss: 8.9120 - val_acc: 0.9162 - val_precision: 0.9313 - val_recall: 0.9790\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 8.3239 - acc: 0.8954 - precision: 0.9422 - recall: 0.9413 - val_loss: 8.3513 - val_acc: 0.9164 - val_precision: 0.9397 - val_recall: 0.9691\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 4.0571 - acc: 0.9133 - precision: 0.9512 - recall: 0.9525 - val_loss: 4.6045 - val_acc: 0.9117 - val_precision: 0.9230 - val_recall: 0.9838\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 6.7592 - acc: 0.8916 - precision: 0.9386 - recall: 0.9410 - val_loss: 8.2294 - val_acc: 0.8714 - val_precision: 0.9656 - val_recall: 0.8885\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.6416 - acc: 0.9072 - precision: 0.9496 - recall: 0.9470 - val_loss: 3.9410 - val_acc: 0.9111 - val_precision: 0.9244 - val_recall: 0.9813\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.0134 - acc: 0.8991 - precision: 0.9437 - recall: 0.9441 - val_loss: 3.5835 - val_acc: 0.8998 - val_precision: 0.9494 - val_recall: 0.9386\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 5.3811 - acc: 0.8995 - precision: 0.9440 - recall: 0.9441 - val_loss: 3.7659 - val_acc: 0.9142 - val_precision: 0.9382 - val_recall: 0.9684\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.1603 - acc: 0.8965 - precision: 0.9422 - recall: 0.9426 - val_loss: 3.9140 - val_acc: 0.8847 - val_precision: 0.9583 - val_recall: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1538f4b80>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model on X_train and binarized labels\n",
    "FSM_NN.fit(X_train, labels, epochs=10, steps_per_epoch=100, validation_data=(X_test, test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 3.9140 - acc: 0.8847 - precision: 0.9583 - recall: 0.9114\n"
     ]
    }
   ],
   "source": [
    "# Getting stats for test data\n",
    "NN_loss, NN_acc, NN_prec, NN_recall = FSM_NN.evaluate(X_test, test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88 \n",
      " Test Precision: 0.96 \n",
      " Test Recall: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Neatly printing evaluation results\n",
    "print(f'Test Accuracy: {NN_acc:.2f} \\n Test Precision: {NN_prec:.2f} \\n Test Recall: {NN_recall:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\n",
    "The neural network does suprisingly well with very few layers and neurons, with some additional layers/tweaking I'm sure we could improve the score. The accuracy is currently below the modeless baseline, and the precision and recall scores indicate that it isn't just choosing one class.\n",
    "\n",
    "# Conclusion\n",
    "Both Catboost and the base Decision tree did well in accuracy, but had poor recall/precision scores. The neural network a little worse accuracy wise, but had very high precision and recall scores. Moving forward this is what I'm planning:\n",
    "\n",
    "1. Spend a very small amount of time on the base decision tree, perhaps iterate only once or twice.\n",
    "\n",
    "2. Catboost will be the way to go here, I'll spend the most time iterating off of this model.\n",
    "\n",
    "3. Spend a moderate amount of time on the neural network, and see if it will do better then Catboost.\n",
    "\n",
    "I think that Catboost has the most potential here, and I'm confident that it will do better then a base decision tree ever could. I think it will be interesting to see what happens with the Neural network. It has good scores, but I'm wondering if it will be able to do much better then Catboost, and if it can, will it be worth the tradeoff of training time and processing power?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}