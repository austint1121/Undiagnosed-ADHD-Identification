{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Keras Neural Net Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "Lets make some NN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "# Created functions from functions.py\n",
    "from functions import metrics as custom_score\n",
    "from functions import improvement as custom_change"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load in cleaned data\n",
    "\n",
    "# Training Data\n",
    "X_train = pd.read_csv('../Data/train/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../Data/train/y_train.csv', index_col=0)\n",
    "\n",
    "# Testing Data\n",
    "X_test = pd.read_csv('../Data/test/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../Data/test/y_test.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 8ms/step - loss: 17.5685 - acc: 0.8690 - precision: 0.3524 - recall: 0.3527 - auc: 0.6444 - val_loss: 8.7116 - val_acc: 0.8818 - val_precision: 0.4185 - val_recall: 0.4319 - val_auc: 0.6907\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 7.4607 - acc: 0.8918 - precision: 0.4648 - recall: 0.4624 - auc: 0.7066 - val_loss: 9.9590 - val_acc: 0.7330 - val_precision: 0.2371 - val_recall: 0.7389 - val_auc: 0.7514\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 5.9152 - acc: 0.8920 - precision: 0.4662 - recall: 0.4726 - auc: 0.7132 - val_loss: 4.5526 - val_acc: 0.8934 - val_precision: 0.4763 - val_recall: 0.5347 - val_auc: 0.7488\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.1188 - acc: 0.9001 - precision: 0.5059 - recall: 0.5085 - auc: 0.7387 - val_loss: 3.7552 - val_acc: 0.8535 - val_precision: 0.3631 - val_recall: 0.5941 - val_auc: 0.7532\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 6.4573 - acc: 0.8925 - precision: 0.4684 - recall: 0.4676 - auc: 0.7171 - val_loss: 3.2103 - val_acc: 0.8958 - val_precision: 0.4861 - val_recall: 0.5198 - val_auc: 0.7428\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 2.6489 - acc: 0.9001 - precision: 0.5060 - recall: 0.5070 - auc: 0.7493 - val_loss: 3.2771 - val_acc: 0.9130 - val_precision: 0.6556 - val_recall: 0.2946 - val_auc: 0.6603\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4.6452 - acc: 0.8914 - precision: 0.4629 - recall: 0.4621 - auc: 0.7155 - val_loss: 2.7864 - val_acc: 0.9111 - val_precision: 0.5836 - val_recall: 0.4233 - val_auc: 0.7104\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 2.6156 - acc: 0.8967 - precision: 0.4894 - recall: 0.4946 - auc: 0.7383 - val_loss: 4.8678 - val_acc: 0.9036 - val_precision: 0.6939 - val_recall: 0.0842 - val_auc: 0.5511\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3.7587 - acc: 0.8968 - precision: 0.4895 - recall: 0.4745 - auc: 0.7252 - val_loss: 2.2593 - val_acc: 0.8854 - val_precision: 0.4481 - val_recall: 0.5718 - val_auc: 0.7792\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3.8368 - acc: 0.8937 - precision: 0.4742 - recall: 0.4745 - auc: 0.7268 - val_loss: 2.1977 - val_acc: 0.8792 - val_precision: 0.4278 - val_recall: 0.5755 - val_auc: 0.7779\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x148a29f10>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Instantiating a NN\n",
    "FSM_NN = keras.Sequential()\n",
    "\n",
    "# Starting small with 30 neurons\n",
    "FSM_NN.add(Dense(30, 'relu', input_shape=(422,)))\n",
    "\n",
    "# 1 output node, for binary classification problem\n",
    "FSM_NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "# Compiling model with accuracy, precision, and recall metrics. Using \"Adam\" as an optimizer\n",
    "FSM_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "FSM_NN.fit(X_train, y_train, epochs=10, steps_per_epoch=100, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 3.6035 - acc: 0.8193 - precision: 0.3298 - recall: 0.7611 - auc: 0.8170\n"
     ]
    }
   ],
   "source": [
    "## Evaluating NN\n",
    "FSM_loss, FSM_acc, FSM_prec, FSM_recall, FSM_AUC = FSM_NN.evaluate(X_test, y_test)\n",
    "\n",
    "results_FSM = {\n",
    "    'Accuracy': FSM_acc,\n",
    "    'Precision': FSM_prec,\n",
    "    'Recall': FSM_recall,\n",
    "    'ROCAUC': FSM_AUC\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "The neural network is boasting some impressively bad precision here, but it is doing it's best with the 30 neurons I provided it. This can definitely be improved, so let's start by giving it more brain power."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Layer NN and more Training Time\n",
    "I'll add some more layers, and give the model more time to train and see if that gives us an improvement."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 2s 11ms/step - loss: 14.4658 - acc: 0.8348 - precision: 0.1739 - recall: 0.1691 - auc: 0.5591 - val_loss: 0.8223 - val_acc: 0.8420 - val_precision: 0.2298 - val_recall: 0.2389 - val_auc: 0.6454\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.9536 - acc: 0.8527 - precision: 0.2250 - recall: 0.1871 - auc: 0.6130 - val_loss: 0.5886 - val_acc: 0.8834 - val_precision: 0.3048 - val_recall: 0.1188 - val_auc: 0.6450\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.6757 - acc: 0.8658 - precision: 0.2621 - recall: 0.1806 - auc: 0.6423 - val_loss: 0.4241 - val_acc: 0.8884 - val_precision: 0.3648 - val_recall: 0.1386 - val_auc: 0.6648\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.5579 - acc: 0.8690 - precision: 0.2452 - recall: 0.1425 - auc: 0.6403 - val_loss: 0.3950 - val_acc: 0.8921 - val_precision: 0.3962 - val_recall: 0.1275 - val_auc: 0.6963\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.3778 - acc: 0.8870 - precision: 0.3525 - recall: 0.1403 - auc: 0.6897 - val_loss: 0.3687 - val_acc: 0.8793 - val_precision: 0.3186 - val_recall: 0.1696 - val_auc: 0.7124\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.3812 - acc: 0.8851 - precision: 0.3523 - recall: 0.1632 - auc: 0.6885 - val_loss: 0.3806 - val_acc: 0.8946 - val_precision: 0.4086 - val_recall: 0.0941 - val_auc: 0.7047\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3534 - acc: 0.8903 - precision: 0.3888 - recall: 0.1483 - auc: 0.7106 - val_loss: 0.3362 - val_acc: 0.8937 - val_precision: 0.4226 - val_recall: 0.1386 - val_auc: 0.7199\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3322 - acc: 0.8934 - precision: 0.4238 - recall: 0.1524 - auc: 0.7314 - val_loss: 0.3454 - val_acc: 0.8861 - val_precision: 0.3762 - val_recall: 0.1918 - val_auc: 0.7217\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3512 - acc: 0.8889 - precision: 0.3890 - recall: 0.1737 - auc: 0.7219 - val_loss: 0.3553 - val_acc: 0.9002 - val_precision: 0.5307 - val_recall: 0.1176 - val_auc: 0.7409\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3052 - acc: 0.8973 - precision: 0.4772 - recall: 0.1688 - auc: 0.7652 - val_loss: 0.3145 - val_acc: 0.9007 - val_precision: 0.5294 - val_recall: 0.1671 - val_auc: 0.7631\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2956 - acc: 0.8993 - precision: 0.5049 - recall: 0.1914 - auc: 0.7856 - val_loss: 0.4901 - val_acc: 0.8963 - val_precision: 0.4713 - val_recall: 0.2030 - val_auc: 0.7955\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3260 - acc: 0.8990 - precision: 0.5007 - recall: 0.2118 - auc: 0.7727 - val_loss: 0.3280 - val_acc: 0.8923 - val_precision: 0.4529 - val_recall: 0.3094 - val_auc: 0.7994\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2842 - acc: 0.8992 - precision: 0.5029 - recall: 0.2121 - auc: 0.8059 - val_loss: 0.2766 - val_acc: 0.8979 - val_precision: 0.4911 - val_recall: 0.2389 - val_auc: 0.8186\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2649 - acc: 0.9036 - precision: 0.5560 - recall: 0.2323 - auc: 0.8261 - val_loss: 0.3695 - val_acc: 0.8524 - val_precision: 0.3399 - val_recall: 0.4876 - val_auc: 0.8013\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2614 - acc: 0.9037 - precision: 0.5514 - recall: 0.2539 - auc: 0.8315 - val_loss: 0.2736 - val_acc: 0.8986 - val_precision: 0.4971 - val_recall: 0.2153 - val_auc: 0.8237\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2516 - acc: 0.9053 - precision: 0.5658 - recall: 0.2704 - auc: 0.8444 - val_loss: 0.2761 - val_acc: 0.8977 - val_precision: 0.4922 - val_recall: 0.3502 - val_auc: 0.8392\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2508 - acc: 0.9079 - precision: 0.5863 - recall: 0.3029 - auc: 0.8453 - val_loss: 0.2599 - val_acc: 0.9033 - val_precision: 0.5398 - val_recall: 0.3020 - val_auc: 0.8472\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2373 - acc: 0.9106 - precision: 0.6118 - recall: 0.3168 - auc: 0.8627 - val_loss: 0.2908 - val_acc: 0.9052 - val_precision: 0.6809 - val_recall: 0.1188 - val_auc: 0.8474\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2477 - acc: 0.9089 - precision: 0.5851 - recall: 0.3385 - auc: 0.8539 - val_loss: 0.2531 - val_acc: 0.9031 - val_precision: 0.5612 - val_recall: 0.1931 - val_auc: 0.8559\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2293 - acc: 0.9120 - precision: 0.6142 - recall: 0.3490 - auc: 0.8735 - val_loss: 0.2496 - val_acc: 0.9068 - val_precision: 0.5498 - val_recall: 0.4369 - val_auc: 0.8734\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2240 - acc: 0.9149 - precision: 0.6276 - recall: 0.3884 - auc: 0.8790 - val_loss: 0.2436 - val_acc: 0.9110 - val_precision: 0.6390 - val_recall: 0.2760 - val_auc: 0.8783\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2233 - acc: 0.9162 - precision: 0.6365 - recall: 0.3986 - auc: 0.8803 - val_loss: 0.2387 - val_acc: 0.9123 - val_precision: 0.6298 - val_recall: 0.3243 - val_auc: 0.8757\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2150 - acc: 0.9189 - precision: 0.6634 - recall: 0.4023 - auc: 0.8889 - val_loss: 0.2383 - val_acc: 0.9118 - val_precision: 0.5952 - val_recall: 0.4022 - val_auc: 0.8789\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2141 - acc: 0.9200 - precision: 0.6725 - recall: 0.4076 - auc: 0.8897 - val_loss: 0.2501 - val_acc: 0.9085 - val_precision: 0.5551 - val_recall: 0.4802 - val_auc: 0.8803\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2265 - acc: 0.9198 - precision: 0.6580 - recall: 0.4302 - auc: 0.8910 - val_loss: 0.2605 - val_acc: 0.9063 - val_precision: 0.6829 - val_recall: 0.1386 - val_auc: 0.8793\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x148f2a490>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a NN\n",
    "NN = keras.Sequential()\n",
    "\n",
    "# 3 layers, double the size at each layer.\n",
    "NN.add(Dense(32, 'relu', input_shape=(422,)))\n",
    "NN.add(Dense(64, 'relu'))\n",
    "NN.add(Dense(128, 'relu'))\n",
    "\n",
    "# 1 output\n",
    "NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "NN.fit(X_train, y_train, epochs=25, steps_per_epoch=100, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2605 - acc: 0.9063 - precision: 0.6829 - recall: 0.1386 - auc: 0.8793\n"
     ]
    }
   ],
   "source": [
    "NN_loss, NN_acc, NN_prec, NN_recall, NN_AUC = NN.evaluate(X_test, y_test)\n",
    "results_NN = {\n",
    "    'Accuracy': NN_acc,\n",
    "    'Precision': NN_prec,\n",
    "    'Recall': NN_recall,\n",
    "    'ROCAUC': NN_AUC\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in Results\n",
      "Accuracy        +0.09\n",
      "Precision       +0.35\n",
      "Recall          -0.62\n",
      "ROCAUC          +0.06\n"
     ]
    }
   ],
   "source": [
    "custom_change(results_FSM, results_NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "An improvement in accuracy, precision and ROCAUC, but a huge drop in Recall. This probably has to do with the data imbalance, I'll address it using oversampling, and class weights, and see what works better."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Weights\n",
    "Setting the initial weights of the classes can help improve performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 3s 13ms/step - loss: 4.2019 - acc: 0.8637 - precision: 0.3227 - recall: 0.3171 - auc: 0.6516 - val_loss: 1.3685 - val_acc: 0.8981 - val_precision: 0.4851 - val_recall: 0.1213 - val_auc: 0.6021\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.0027 - acc: 0.8736 - precision: 0.3647 - recall: 0.3369 - auc: 0.6939 - val_loss: 0.7357 - val_acc: 0.8579 - val_precision: 0.3589 - val_recall: 0.5149 - val_auc: 0.7721\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.8055 - acc: 0.8776 - precision: 0.3828 - recall: 0.3434 - auc: 0.7077 - val_loss: 0.4691 - val_acc: 0.8760 - val_precision: 0.3882 - val_recall: 0.3911 - val_auc: 0.7779\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6751 - acc: 0.8801 - precision: 0.3932 - recall: 0.3431 - auc: 0.7299 - val_loss: 0.4883 - val_acc: 0.8455 - val_precision: 0.3301 - val_recall: 0.5124 - val_auc: 0.7693\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3684 - acc: 0.8972 - precision: 0.4886 - recall: 0.3642 - auc: 0.7907 - val_loss: 0.3915 - val_acc: 0.9076 - val_precision: 0.6144 - val_recall: 0.2327 - val_auc: 0.7939\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4343 - acc: 0.8927 - precision: 0.4615 - recall: 0.3673 - auc: 0.7714 - val_loss: 0.3982 - val_acc: 0.8646 - val_precision: 0.3884 - val_recall: 0.5879 - val_auc: 0.8175\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3056 - acc: 0.9049 - precision: 0.5422 - recall: 0.3819 - auc: 0.8183 - val_loss: 0.3270 - val_acc: 0.8951 - val_precision: 0.4810 - val_recall: 0.4691 - val_auc: 0.8345\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3134 - acc: 0.9034 - precision: 0.5302 - recall: 0.3915 - auc: 0.8184 - val_loss: 0.2907 - val_acc: 0.9031 - val_precision: 0.5278 - val_recall: 0.3998 - val_auc: 0.8111\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2915 - acc: 0.9071 - precision: 0.5566 - recall: 0.3976 - auc: 0.8268 - val_loss: 0.2898 - val_acc: 0.9072 - val_precision: 0.5645 - val_recall: 0.3626 - val_auc: 0.8279\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2628 - acc: 0.9117 - precision: 0.5882 - recall: 0.4215 - auc: 0.8461 - val_loss: 0.2637 - val_acc: 0.9092 - val_precision: 0.5649 - val_recall: 0.4468 - val_auc: 0.8553\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3203 - acc: 0.9058 - precision: 0.5457 - recall: 0.4051 - auc: 0.8187 - val_loss: 0.3510 - val_acc: 0.8725 - val_precision: 0.4142 - val_recall: 0.6275 - val_auc: 0.8493\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2638 - acc: 0.9114 - precision: 0.5864 - recall: 0.4184 - auc: 0.8496 - val_loss: 0.2772 - val_acc: 0.9053 - val_precision: 0.5334 - val_recall: 0.5136 - val_auc: 0.8585\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2517 - acc: 0.9148 - precision: 0.6146 - recall: 0.4227 - auc: 0.8545 - val_loss: 0.6211 - val_acc: 0.7428 - val_precision: 0.2547 - val_recall: 0.8007 - val_auc: 0.8502\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2716 - acc: 0.9110 - precision: 0.5817 - recall: 0.4255 - auc: 0.8484 - val_loss: 0.2424 - val_acc: 0.9106 - val_precision: 0.5870 - val_recall: 0.3923 - val_auc: 0.8716\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2592 - acc: 0.9113 - precision: 0.5858 - recall: 0.4187 - auc: 0.8542 - val_loss: 0.3077 - val_acc: 0.8804 - val_precision: 0.4370 - val_recall: 0.6312 - val_auc: 0.8704\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2524 - acc: 0.9116 - precision: 0.5868 - recall: 0.4261 - auc: 0.8608 - val_loss: 0.3177 - val_acc: 0.8876 - val_precision: 0.4574 - val_recall: 0.5978 - val_auc: 0.8595\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.2343 - acc: 0.9158 - precision: 0.6173 - recall: 0.4401 - auc: 0.8743 - val_loss: 0.2442 - val_acc: 0.9100 - val_precision: 0.6067 - val_recall: 0.3131 - val_auc: 0.8715\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2270 - acc: 0.9190 - precision: 0.6455 - recall: 0.4404 - auc: 0.8822 - val_loss: 0.2555 - val_acc: 0.9174 - val_precision: 0.6407 - val_recall: 0.4171 - val_auc: 0.8762\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2479 - acc: 0.9143 - precision: 0.6055 - recall: 0.4364 - auc: 0.8678 - val_loss: 0.2666 - val_acc: 0.9006 - val_precision: 0.5082 - val_recall: 0.5359 - val_auc: 0.8804\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2254 - acc: 0.9176 - precision: 0.6314 - recall: 0.4441 - auc: 0.8860 - val_loss: 0.3202 - val_acc: 0.9138 - val_precision: 0.7381 - val_recall: 0.2302 - val_auc: 0.8547\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2277 - acc: 0.9188 - precision: 0.6410 - recall: 0.4478 - auc: 0.8819 - val_loss: 0.2344 - val_acc: 0.9142 - val_precision: 0.6401 - val_recall: 0.3478 - val_auc: 0.8731\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2273 - acc: 0.9179 - precision: 0.6363 - recall: 0.4395 - auc: 0.8834 - val_loss: 0.2279 - val_acc: 0.9179 - val_precision: 0.6402 - val_recall: 0.4295 - val_auc: 0.8890\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2198 - acc: 0.9212 - precision: 0.6598 - recall: 0.4559 - auc: 0.8886 - val_loss: 0.2272 - val_acc: 0.9165 - val_precision: 0.6076 - val_recall: 0.4926 - val_auc: 0.8927\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2067 - acc: 0.9242 - precision: 0.6828 - recall: 0.4673 - auc: 0.8996 - val_loss: 0.2370 - val_acc: 0.9157 - val_precision: 0.6790 - val_recall: 0.3168 - val_auc: 0.8860\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2193 - acc: 0.9209 - precision: 0.6573 - recall: 0.4556 - auc: 0.8932 - val_loss: 0.2272 - val_acc: 0.9190 - val_precision: 0.6594 - val_recall: 0.4121 - val_auc: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x148dcb100>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class bias = log([pos/neg])\n",
    "initial_bias = np.log([4306/42777])\n",
    "\n",
    "# Creating tf init object from bias\n",
    "output_bias = tf.initializers.Constant(initial_bias)\n",
    "# Instantiating a NN\n",
    "IW_NN = keras.Sequential()\n",
    "\n",
    "# 3 layers, double the size at each layer.\n",
    "IW_NN.add(Dense(32, 'relu', input_shape=(422,)))\n",
    "IW_NN.add(Dense(64, 'relu'))\n",
    "IW_NN.add(Dense(128, 'relu'))\n",
    "\n",
    "# 1 output\n",
    "IW_NN.add(Dense(1, 'sigmoid', bias_initializer=output_bias))\n",
    "\n",
    "IW_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "IW_NN.fit(X_train, y_train, epochs=25, steps_per_epoch=100, validation_data=(X_test, y_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.2272 - acc: 0.9190 - precision: 0.6594 - recall: 0.4121 - auc: 0.8914\n"
     ]
    }
   ],
   "source": [
    "IW_NN_loss, IW_NN_acc, IW_NN_prec, IW_NN_recall, IW_NN_AUC = IW_NN.evaluate(X_test, y_test)\n",
    "results_IW_NN = {\n",
    "    'Accuracy': IW_NN_acc,\n",
    "    'Precision': IW_NN_prec,\n",
    "    'Recall': IW_NN_recall,\n",
    "    'ROCAUC': IW_NN_AUC\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in Results\n",
      "Accuracy        +0.03\n",
      "Precision       +0.21\n",
      "Recall          -0.25\n",
      "ROCAUC          +0.02\n"
     ]
    }
   ],
   "source": [
    "custom_change(results_NN, IW_NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weighted NN\n",
    "Now, let's try setting initial weights, and adding class weights."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.55\n",
      "Weight for class 1: 5.47\n"
     ]
    }
   ],
   "source": [
    "pos = 4306\n",
    "neg = 42777\n",
    "total = pos+neg\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 3s 12ms/step - loss: 6.6995 - acc: 0.6834 - precision: 0.1990 - recall: 0.7042 - auc: 0.7274 - val_loss: 1.8926 - val_acc: 0.7367 - val_precision: 0.2343 - val_recall: 0.7067 - val_auc: 0.7757\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 1.8433 - acc: 0.7114 - precision: 0.2204 - recall: 0.7312 - auc: 0.7836 - val_loss: 3.2175 - val_acc: 0.4537 - val_precision: 0.1484 - val_recall: 0.9282 - val_auc: 0.7523\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.2188 - acc: 0.7281 - precision: 0.2349 - recall: 0.7488 - auc: 0.8150 - val_loss: 1.3787 - val_acc: 0.7045 - val_precision: 0.2250 - val_recall: 0.7859 - val_auc: 0.8041\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 1.1648 - acc: 0.7406 - precision: 0.2464 - recall: 0.7606 - auc: 0.8239 - val_loss: 0.5308 - val_acc: 0.9018 - val_precision: 0.5182 - val_recall: 0.4220 - val_auc: 0.8168\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.1165 - acc: 0.7418 - precision: 0.2461 - recall: 0.7532 - auc: 0.8231 - val_loss: 0.6915 - val_acc: 0.8075 - val_precision: 0.3064 - val_recall: 0.7141 - val_auc: 0.8429\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8311 - acc: 0.7577 - precision: 0.2636 - recall: 0.7783 - auc: 0.8457 - val_loss: 0.9366 - val_acc: 0.7020 - val_precision: 0.2297 - val_recall: 0.8267 - val_auc: 0.8404\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.7300 - acc: 0.7739 - precision: 0.2789 - recall: 0.7804 - auc: 0.8551 - val_loss: 0.6520 - val_acc: 0.7800 - val_precision: 0.2826 - val_recall: 0.7636 - val_auc: 0.8527\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.6566 - acc: 0.7766 - precision: 0.2814 - recall: 0.7789 - auc: 0.8610 - val_loss: 1.0677 - val_acc: 0.5848 - val_precision: 0.1849 - val_recall: 0.9109 - val_auc: 0.8620\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.6006 - acc: 0.7813 - precision: 0.2887 - recall: 0.7947 - auc: 0.8686 - val_loss: 1.1909 - val_acc: 0.5823 - val_precision: 0.1842 - val_recall: 0.9121 - val_auc: 0.8647\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.7924 - precision: 0.3011 - recall: 0.7975 - auc: 0.8761 - val_loss: 0.5381 - val_acc: 0.8079 - val_precision: 0.3183 - val_recall: 0.7871 - val_auc: 0.8746\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5393 - acc: 0.7921 - precision: 0.3015 - recall: 0.8024 - auc: 0.8770 - val_loss: 0.3183 - val_acc: 0.8901 - val_precision: 0.4574 - val_recall: 0.4653 - val_auc: 0.8510\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.5204 - acc: 0.7962 - precision: 0.3059 - recall: 0.7999 - auc: 0.8801 - val_loss: 0.4566 - val_acc: 0.8337 - val_precision: 0.3472 - val_recall: 0.7314 - val_auc: 0.8631\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4901 - acc: 0.8019 - precision: 0.3138 - recall: 0.8080 - auc: 0.8855 - val_loss: 0.3494 - val_acc: 0.8774 - val_precision: 0.4267 - val_recall: 0.6163 - val_auc: 0.8629\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5092 - acc: 0.8014 - precision: 0.3133 - recall: 0.8092 - auc: 0.8814 - val_loss: 0.5099 - val_acc: 0.8301 - val_precision: 0.3491 - val_recall: 0.7859 - val_auc: 0.8878\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.4815 - acc: 0.8033 - precision: 0.3157 - recall: 0.8095 - auc: 0.8882 - val_loss: 0.6679 - val_acc: 0.7536 - val_precision: 0.2727 - val_recall: 0.8614 - val_auc: 0.8827\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.5513 - acc: 0.7762 - precision: 0.2813 - recall: 0.7804 - auc: 0.8616 - val_loss: 0.6365 - val_acc: 0.7209 - val_precision: 0.2481 - val_recall: 0.8663 - val_auc: 0.8704\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.4751 - acc: 0.8125 - precision: 0.3237 - recall: 0.7845 - auc: 0.8830 - val_loss: 0.6703 - val_acc: 0.7605 - val_precision: 0.2773 - val_recall: 0.8515 - val_auc: 0.8739\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.5077 - acc: 0.8055 - precision: 0.3124 - recall: 0.7690 - auc: 0.8704 - val_loss: 0.6464 - val_acc: 0.7328 - val_precision: 0.2580 - val_recall: 0.8750 - val_auc: 0.8800\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4572 - acc: 0.8321 - precision: 0.3530 - recall: 0.7928 - auc: 0.8949 - val_loss: 0.4445 - val_acc: 0.8308 - val_precision: 0.3530 - val_recall: 0.8069 - val_auc: 0.8903\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.4374 - acc: 0.8350 - precision: 0.3593 - recall: 0.8077 - auc: 0.8982 - val_loss: 0.5168 - val_acc: 0.8072 - val_precision: 0.3249 - val_recall: 0.8403 - val_auc: 0.8931\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.4471 - acc: 0.8242 - precision: 0.3425 - recall: 0.8030 - auc: 0.8915 - val_loss: 0.5286 - val_acc: 0.8167 - val_precision: 0.3347 - val_recall: 0.8218 - val_auc: 0.8918\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.4330 - acc: 0.8278 - precision: 0.3471 - recall: 0.7981 - auc: 0.8962 - val_loss: 0.3856 - val_acc: 0.8688 - val_precision: 0.4156 - val_recall: 0.7314 - val_auc: 0.8960\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4517 - acc: 0.8415 - precision: 0.3678 - recall: 0.7903 - auc: 0.8966 - val_loss: 0.3849 - val_acc: 0.8700 - val_precision: 0.4175 - val_recall: 0.7203 - val_auc: 0.8957\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4284 - acc: 0.8331 - precision: 0.3575 - recall: 0.8167 - auc: 0.9017 - val_loss: 0.3354 - val_acc: 0.8774 - val_precision: 0.4360 - val_recall: 0.7203 - val_auc: 0.9001\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.4134 - acc: 0.8479 - precision: 0.3794 - recall: 0.7941 - auc: 0.9057 - val_loss: 0.3678 - val_acc: 0.8749 - val_precision: 0.4312 - val_recall: 0.7413 - val_auc: 0.8964\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1496f01f0>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_NN = keras.Sequential()\n",
    "\n",
    "# 3 layers, double the size at each layer.\n",
    "weighted_NN.add(Dense(32, 'relu', input_shape=(422,)))\n",
    "weighted_NN.add(Dense(64, 'relu'))\n",
    "weighted_NN.add(Dense(128, 'relu'))\n",
    "\n",
    "# 1 output\n",
    "weighted_NN.add(Dense(1, 'sigmoid', bias_initializer=output_bias))\n",
    "\n",
    "weighted_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "weighted_NN.fit(X_train, y_train, epochs=25, steps_per_epoch=100, validation_data=(X_test, y_test), class_weight=class_weight)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3678 - acc: 0.8749 - precision: 0.4312 - recall: 0.7413 - auc: 0.8964\n"
     ]
    }
   ],
   "source": [
    "weighted_NN_loss, weighted_NN_acc, weighted_NN_prec, weighted_NN_recall, weighted_NN_AUC = weighted_NN.evaluate(X_test, y_test)\n",
    "results_weighted_NN = {\n",
    "    'Accuracy': weighted_NN_acc,\n",
    "    'Precision': weighted_NN_prec,\n",
    "    'Recall': weighted_NN_recall,\n",
    "    'ROCAUC': weighted_NN_AUC\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in Results\n",
      "Accuracy        -0.04\n",
      "Precision       -0.23\n",
      "Recall          +0.33\n",
      "ROCAUC          +0.01\n"
     ]
    }
   ],
   "source": [
    "custom_change(results_NN, results_weighted_NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Oversample Nerual Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Initiate Over sampler\n",
    "ros = RandomOverSampler(random_state=15)\n",
    "\n",
    "# Applying ONLY to training set to prevent data leakage.\n",
    "X_train_os, y_train_os = ros.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 3s 13ms/step - loss: 7.3386 - acc: 0.6670 - precision: 0.6689 - recall: 0.6612 - auc: 0.7017 - val_loss: 1.9464 - val_acc: 0.6485 - val_precision: 0.1876 - val_recall: 0.7426 - val_auc: 0.7534\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 1.2326 - acc: 0.7120 - precision: 0.7135 - recall: 0.7086 - auc: 0.7854 - val_loss: 2.2870 - val_acc: 0.4579 - val_precision: 0.1483 - val_recall: 0.9183 - val_auc: 0.7808\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.9519 - acc: 0.7346 - precision: 0.7343 - recall: 0.7351 - auc: 0.8144 - val_loss: 0.5930 - val_acc: 0.8415 - val_precision: 0.3390 - val_recall: 0.5965 - val_auc: 0.8154\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6955 - acc: 0.7648 - precision: 0.7669 - recall: 0.7607 - auc: 0.8451 - val_loss: 1.2802 - val_acc: 0.5361 - val_precision: 0.1685 - val_recall: 0.9109 - val_auc: 0.8318\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6334 - acc: 0.7758 - precision: 0.7761 - recall: 0.7754 - auc: 0.8583 - val_loss: 0.4758 - val_acc: 0.8562 - val_precision: 0.3752 - val_recall: 0.6324 - val_auc: 0.8395\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.5201 - acc: 0.7960 - precision: 0.7980 - recall: 0.7926 - auc: 0.8783 - val_loss: 0.4462 - val_acc: 0.8717 - val_precision: 0.4137 - val_recall: 0.6436 - val_auc: 0.8547\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.5043 - acc: 0.8000 - precision: 0.8017 - recall: 0.7971 - auc: 0.8830 - val_loss: 0.8341 - val_acc: 0.7150 - val_precision: 0.2434 - val_recall: 0.8614 - val_auc: 0.8645\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.4626 - acc: 0.8127 - precision: 0.8150 - recall: 0.8090 - auc: 0.8934 - val_loss: 0.4543 - val_acc: 0.8471 - val_precision: 0.3672 - val_recall: 0.7067 - val_auc: 0.8591\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.4552 - acc: 0.8137 - precision: 0.8163 - recall: 0.8095 - auc: 0.8946 - val_loss: 0.8769 - val_acc: 0.6589 - val_precision: 0.2144 - val_recall: 0.8899 - val_auc: 0.8641\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.4233 - acc: 0.8232 - precision: 0.8251 - recall: 0.8205 - auc: 0.9030 - val_loss: 0.4268 - val_acc: 0.8586 - val_precision: 0.3906 - val_recall: 0.7092 - val_auc: 0.8662\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.4179 - acc: 0.8254 - precision: 0.8282 - recall: 0.8210 - auc: 0.9052 - val_loss: 0.5169 - val_acc: 0.8216 - val_precision: 0.3377 - val_recall: 0.7946 - val_auc: 0.8679\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3797 - acc: 0.8383 - precision: 0.8421 - recall: 0.8328 - auc: 0.9156 - val_loss: 0.4329 - val_acc: 0.8515 - val_precision: 0.3802 - val_recall: 0.7426 - val_auc: 0.8693\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3634 - acc: 0.8440 - precision: 0.8476 - recall: 0.8388 - auc: 0.9217 - val_loss: 0.3105 - val_acc: 0.9021 - val_precision: 0.5143 - val_recall: 0.5792 - val_auc: 0.8686\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3864 - acc: 0.8366 - precision: 0.8395 - recall: 0.8323 - auc: 0.9150 - val_loss: 0.8005 - val_acc: 0.6657 - val_precision: 0.2158 - val_recall: 0.8750 - val_auc: 0.8684\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3927 - acc: 0.8347 - precision: 0.8361 - recall: 0.8326 - auc: 0.9136 - val_loss: 0.4152 - val_acc: 0.8608 - val_precision: 0.3981 - val_recall: 0.7351 - val_auc: 0.8722\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3675 - acc: 0.8450 - precision: 0.8479 - recall: 0.8408 - auc: 0.9207 - val_loss: 0.7156 - val_acc: 0.7066 - val_precision: 0.2374 - val_recall: 0.8589 - val_auc: 0.8704\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3499 - acc: 0.8484 - precision: 0.8514 - recall: 0.8441 - auc: 0.9261 - val_loss: 0.3420 - val_acc: 0.8857 - val_precision: 0.4557 - val_recall: 0.6683 - val_auc: 0.8755\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.3638 - acc: 0.8444 - precision: 0.8444 - recall: 0.8444 - auc: 0.9217 - val_loss: 0.3386 - val_acc: 0.8855 - val_precision: 0.4546 - val_recall: 0.6572 - val_auc: 0.8690\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3510 - acc: 0.8481 - precision: 0.8498 - recall: 0.8457 - auc: 0.9257 - val_loss: 0.4058 - val_acc: 0.8591 - val_precision: 0.3933 - val_recall: 0.7228 - val_auc: 0.8752\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3442 - acc: 0.8509 - precision: 0.8524 - recall: 0.8487 - auc: 0.9278 - val_loss: 0.4101 - val_acc: 0.8613 - val_precision: 0.3975 - val_recall: 0.7203 - val_auc: 0.8696\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.3419 - acc: 0.8527 - precision: 0.8548 - recall: 0.8497 - auc: 0.9288 - val_loss: 0.3217 - val_acc: 0.8919 - val_precision: 0.4748 - val_recall: 0.6423 - val_auc: 0.8670\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3468 - acc: 0.8514 - precision: 0.8516 - recall: 0.8512 - auc: 0.9276 - val_loss: 0.6576 - val_acc: 0.7553 - val_precision: 0.2708 - val_recall: 0.8379 - val_auc: 0.8745\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3437 - acc: 0.8530 - precision: 0.8536 - recall: 0.8522 - auc: 0.9291 - val_loss: 0.4545 - val_acc: 0.8531 - val_precision: 0.3851 - val_recall: 0.7574 - val_auc: 0.8778\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3272 - acc: 0.8575 - precision: 0.8595 - recall: 0.8546 - auc: 0.9341 - val_loss: 0.3812 - val_acc: 0.8679 - val_precision: 0.4103 - val_recall: 0.6993 - val_auc: 0.8687\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3223 - acc: 0.8610 - precision: 0.8612 - recall: 0.8608 - auc: 0.9359 - val_loss: 0.3518 - val_acc: 0.8847 - val_precision: 0.4521 - val_recall: 0.6597 - val_auc: 0.8728\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x147c09970>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a OS NN\n",
    "OS_NN = keras.Sequential()\n",
    "\n",
    "# 3 layers, double the size at each layer.\n",
    "OS_NN.add(Dense(32, 'relu', input_shape=(422,)))\n",
    "OS_NN.add(Dense(64, 'relu'))\n",
    "OS_NN.add(Dense(128, 'relu'))\n",
    "\n",
    "# 1 output\n",
    "OS_NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "OS_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "OS_NN.fit(X_train_os, y_train_os, epochs=25, steps_per_epoch=100, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3518 - acc: 0.8847 - precision: 0.4521 - recall: 0.6597 - auc: 0.8728\n"
     ]
    }
   ],
   "source": [
    "OS_NN_loss, OS_NN_acc, OS_NN_prec, OS_NN_recall, OS_NN_AUC = OS_NN.evaluate(X_test, y_test)\n",
    "results_OS_NN = {\n",
    "    'Accuracy': OS_NN_acc,\n",
    "    'Precision': OS_NN_prec,\n",
    "    'Recall': OS_NN_recall,\n",
    "    'ROCAUC': OS_NN_AUC\n",
    "\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in Results\n",
      "Accuracy        -0.02\n",
      "Precision       -0.23\n",
      "Recall          +0.52\n",
      "ROCAUC          -0.01\n"
     ]
    }
   ],
   "source": [
    "custom_change(results_NN, results_OS_NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "The oversample seems to have balanced things out. We have decent AUC so we aren't far off the mark, but precision is now below 0.5 which is a bit rough. There is also a large difference between the training scores and testing scores, so our model is overfitting, let's just go ahead and adjust that now."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA\n",
    " I think there is a bigger issue here as well. There are 422 features in this dataset right now. I imagine only about ~200 of those columns actually are providing useful information. Let's perform PCA on the model and see if it changes anything."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_train_os)\n",
    "X_te_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=.9)\n",
    "X_train_transformed = pca.fit_transform(X_tr_scaled)\n",
    "X_test_transformed = pca.transform(X_te_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "110"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 5s 27ms/step - loss: 0.4372 - acc: 0.7962 - precision: 0.7963 - recall: 0.7960 - auc: 0.8797 - val_loss: 0.4291 - val_acc: 0.8232 - val_precision: 0.3454 - val_recall: 0.8354 - val_auc: 0.9051\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.3312 - acc: 0.8581 - precision: 0.8613 - recall: 0.8537 - auc: 0.9320 - val_loss: 0.3319 - val_acc: 0.8635 - val_precision: 0.4081 - val_recall: 0.7748 - val_auc: 0.9090\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.3048 - acc: 0.8710 - precision: 0.8674 - recall: 0.8759 - auc: 0.9419 - val_loss: 0.3245 - val_acc: 0.8631 - val_precision: 0.4084 - val_recall: 0.7859 - val_auc: 0.9090\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2838 - acc: 0.8816 - precision: 0.8720 - recall: 0.8945 - auc: 0.9489 - val_loss: 0.3928 - val_acc: 0.8292 - val_precision: 0.3540 - val_recall: 0.8342 - val_auc: 0.9089\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2640 - acc: 0.8924 - precision: 0.8770 - recall: 0.9129 - auc: 0.9549 - val_loss: 0.3503 - val_acc: 0.8537 - val_precision: 0.3898 - val_recall: 0.7884 - val_auc: 0.9021\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.2462 - acc: 0.9030 - precision: 0.8851 - recall: 0.9263 - auc: 0.9599 - val_loss: 0.3500 - val_acc: 0.8552 - val_precision: 0.3915 - val_recall: 0.7772 - val_auc: 0.8969\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2303 - acc: 0.9100 - precision: 0.8896 - recall: 0.9362 - auc: 0.9639 - val_loss: 0.3340 - val_acc: 0.8693 - val_precision: 0.4178 - val_recall: 0.7426 - val_auc: 0.8920\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.2139 - acc: 0.9196 - precision: 0.8976 - recall: 0.9474 - auc: 0.9679 - val_loss: 0.3556 - val_acc: 0.8616 - val_precision: 0.4026 - val_recall: 0.7599 - val_auc: 0.8849\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1997 - acc: 0.9264 - precision: 0.9031 - recall: 0.9555 - auc: 0.9711 - val_loss: 0.3463 - val_acc: 0.8734 - val_precision: 0.4257 - val_recall: 0.7203 - val_auc: 0.8762\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1874 - acc: 0.9316 - precision: 0.9076 - recall: 0.9611 - auc: 0.9738 - val_loss: 0.3763 - val_acc: 0.8679 - val_precision: 0.4138 - val_recall: 0.7339 - val_auc: 0.8731\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1776 - acc: 0.9377 - precision: 0.9126 - recall: 0.9680 - auc: 0.9758 - val_loss: 0.3907 - val_acc: 0.8650 - val_precision: 0.4052 - val_recall: 0.7141 - val_auc: 0.8681\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1662 - acc: 0.9424 - precision: 0.9171 - recall: 0.9727 - auc: 0.9781 - val_loss: 0.3877 - val_acc: 0.8778 - val_precision: 0.4336 - val_recall: 0.6795 - val_auc: 0.8618\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1561 - acc: 0.9476 - precision: 0.9221 - recall: 0.9777 - auc: 0.9802 - val_loss: 0.4270 - val_acc: 0.8615 - val_precision: 0.3970 - val_recall: 0.7104 - val_auc: 0.8586\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1481 - acc: 0.9513 - precision: 0.9260 - recall: 0.9810 - auc: 0.9819 - val_loss: 0.4469 - val_acc: 0.8643 - val_precision: 0.4018 - val_recall: 0.6993 - val_auc: 0.8573\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1388 - acc: 0.9548 - precision: 0.9294 - recall: 0.9843 - auc: 0.9834 - val_loss: 0.4405 - val_acc: 0.8767 - val_precision: 0.4291 - val_recall: 0.6634 - val_auc: 0.8528\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1318 - acc: 0.9577 - precision: 0.9332 - recall: 0.9860 - auc: 0.9848 - val_loss: 0.4674 - val_acc: 0.8727 - val_precision: 0.4183 - val_recall: 0.6621 - val_auc: 0.8503\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1273 - acc: 0.9596 - precision: 0.9356 - recall: 0.9872 - auc: 0.9856 - val_loss: 0.4774 - val_acc: 0.8815 - val_precision: 0.4421 - val_recall: 0.6522 - val_auc: 0.8464\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.1192 - acc: 0.9633 - precision: 0.9404 - recall: 0.9894 - auc: 0.9869 - val_loss: 0.4917 - val_acc: 0.8788 - val_precision: 0.4322 - val_recall: 0.6312 - val_auc: 0.8455\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.1123 - acc: 0.9656 - precision: 0.9436 - recall: 0.9905 - auc: 0.9881 - val_loss: 0.5113 - val_acc: 0.8813 - val_precision: 0.4393 - val_recall: 0.6275 - val_auc: 0.8415\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1072 - acc: 0.9679 - precision: 0.9466 - recall: 0.9919 - auc: 0.9889 - val_loss: 0.5403 - val_acc: 0.8745 - val_precision: 0.4196 - val_recall: 0.6262 - val_auc: 0.8383\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.1028 - acc: 0.9696 - precision: 0.9485 - recall: 0.9932 - auc: 0.9896 - val_loss: 0.5592 - val_acc: 0.8779 - val_precision: 0.4299 - val_recall: 0.6337 - val_auc: 0.8370\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0975 - acc: 0.9716 - precision: 0.9515 - recall: 0.9938 - auc: 0.9905 - val_loss: 0.5736 - val_acc: 0.8818 - val_precision: 0.4400 - val_recall: 0.6176 - val_auc: 0.8351\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0926 - acc: 0.9730 - precision: 0.9533 - recall: 0.9948 - auc: 0.9912 - val_loss: 0.5843 - val_acc: 0.8883 - val_precision: 0.4583 - val_recall: 0.5718 - val_auc: 0.8289\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.0901 - acc: 0.9738 - precision: 0.9551 - recall: 0.9943 - auc: 0.9917 - val_loss: 0.6091 - val_acc: 0.8848 - val_precision: 0.4490 - val_recall: 0.6101 - val_auc: 0.8307\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.0855 - acc: 0.9752 - precision: 0.9568 - recall: 0.9953 - auc: 0.9924 - val_loss: 0.6367 - val_acc: 0.8790 - val_precision: 0.4320 - val_recall: 0.6213 - val_auc: 0.8275\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x14a7f8d60>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a OS NN\n",
    "pca_NN = keras.Sequential()\n",
    "\n",
    "# 3 layers, double the size at each layer, and 30% dropout at each layer\n",
    "pca_NN.add(Dense(32, 'relu', input_shape=(110,)))\n",
    "pca_NN.add(Dense(64, 'relu'))\n",
    "pca_NN.add(Dense(128, 'relu'))\n",
    "# 1 output\n",
    "pca_NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "pca_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "pca_NN.fit(X_train_transformed, y_train_os, epochs=25, steps_per_epoch=100, validation_data=(X_test_transformed, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6367 - acc: 0.8790 - precision: 0.4320 - recall: 0.6213 - auc: 0.8275\n"
     ]
    }
   ],
   "source": [
    "# Saving results of the evaluate() function\n",
    "pca_NN_loss, pca_NN_acc, pca_NN_prec, pca_NN_recall, pca_NN_AUC = pca_NN.evaluate(X_test_transformed, y_test)\n",
    "\n",
    "# Placing results in a dictionary for ease of comparison.\n",
    "results_pca_NN = {\n",
    "    'Accuracy': pca_NN_acc,\n",
    "    'Precision': pca_NN_prec,\n",
    "    'Recall': pca_NN_recall,\n",
    "    'ROCAUC': pca_NN_AUC\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in Results\n",
      "Accuracy        -0.01\n",
      "Precision       -0.02\n",
      "Recall          -0.04\n",
      "ROCAUC          -0.05\n"
     ]
    }
   ],
   "source": [
    "# Printing change from the previous model's results\n",
    "custom_change(results_OS_NN, results_pca_NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "A slight drop in performance, probably from the loss of explainability, however, it looks like there is less overfitting occuring."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MISC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50/50 [==============================] - 3s 25ms/step - loss: 0.4965 - acc: 0.7457 - precision: 0.7361 - recall: 0.7660 - auc: 0.8365 - val_loss: 0.4284 - val_acc: 0.8358 - val_precision: 0.3575 - val_recall: 0.7809 - val_auc: 0.8831\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.3609 - acc: 0.8390 - precision: 0.8526 - recall: 0.8197 - auc: 0.9201 - val_loss: 0.3768 - val_acc: 0.8481 - val_precision: 0.3804 - val_recall: 0.7970 - val_auc: 0.9015\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.3244 - acc: 0.8588 - precision: 0.8608 - recall: 0.8560 - auc: 0.9349 - val_loss: 0.3604 - val_acc: 0.8517 - val_precision: 0.3873 - val_recall: 0.7995 - val_auc: 0.9068\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.3043 - acc: 0.8702 - precision: 0.8635 - recall: 0.8794 - auc: 0.9423 - val_loss: 0.3714 - val_acc: 0.8357 - val_precision: 0.3618 - val_recall: 0.8168 - val_auc: 0.9060\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2875 - acc: 0.8796 - precision: 0.8678 - recall: 0.8957 - auc: 0.9480 - val_loss: 0.3606 - val_acc: 0.8464 - val_precision: 0.3781 - val_recall: 0.8045 - val_auc: 0.9041\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2720 - acc: 0.8873 - precision: 0.8722 - recall: 0.9076 - auc: 0.9530 - val_loss: 0.3382 - val_acc: 0.8556 - val_precision: 0.3932 - val_recall: 0.7859 - val_auc: 0.9016\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2576 - acc: 0.8941 - precision: 0.8764 - recall: 0.9175 - auc: 0.9571 - val_loss: 0.3343 - val_acc: 0.8605 - val_precision: 0.4012 - val_recall: 0.7686 - val_auc: 0.8965\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2459 - acc: 0.9009 - precision: 0.8812 - recall: 0.9267 - auc: 0.9604 - val_loss: 0.3222 - val_acc: 0.8658 - val_precision: 0.4101 - val_recall: 0.7450 - val_auc: 0.8942\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2332 - acc: 0.9081 - precision: 0.8877 - recall: 0.9343 - auc: 0.9638 - val_loss: 0.3409 - val_acc: 0.8601 - val_precision: 0.3991 - val_recall: 0.7562 - val_auc: 0.8911\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2223 - acc: 0.9137 - precision: 0.8902 - recall: 0.9438 - auc: 0.9665 - val_loss: 0.3449 - val_acc: 0.8619 - val_precision: 0.4013 - val_recall: 0.7426 - val_auc: 0.8860\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.2114 - acc: 0.9186 - precision: 0.8946 - recall: 0.9491 - auc: 0.9691 - val_loss: 0.3830 - val_acc: 0.8485 - val_precision: 0.3773 - val_recall: 0.7649 - val_auc: 0.8856\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.2030 - acc: 0.9225 - precision: 0.8984 - recall: 0.9528 - auc: 0.9711 - val_loss: 0.3325 - val_acc: 0.8802 - val_precision: 0.4408 - val_recall: 0.6869 - val_auc: 0.8761\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1932 - acc: 0.9281 - precision: 0.9036 - recall: 0.9585 - auc: 0.9733 - val_loss: 0.3668 - val_acc: 0.8639 - val_precision: 0.4041 - val_recall: 0.7277 - val_auc: 0.8782\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1842 - acc: 0.9329 - precision: 0.9073 - recall: 0.9643 - auc: 0.9752 - val_loss: 0.3750 - val_acc: 0.8646 - val_precision: 0.4045 - val_recall: 0.7153 - val_auc: 0.8718\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.1763 - acc: 0.9363 - precision: 0.9108 - recall: 0.9673 - auc: 0.9768 - val_loss: 0.3672 - val_acc: 0.8750 - val_precision: 0.4275 - val_recall: 0.6931 - val_auc: 0.8713\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1683 - acc: 0.9410 - precision: 0.9153 - recall: 0.9720 - auc: 0.9785 - val_loss: 0.3914 - val_acc: 0.8674 - val_precision: 0.4095 - val_recall: 0.7030 - val_auc: 0.8690\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1608 - acc: 0.9451 - precision: 0.9183 - recall: 0.9771 - auc: 0.9798 - val_loss: 0.3920 - val_acc: 0.8735 - val_precision: 0.4231 - val_recall: 0.6881 - val_auc: 0.8645\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1555 - acc: 0.9464 - precision: 0.9209 - recall: 0.9766 - auc: 0.9810 - val_loss: 0.3931 - val_acc: 0.8820 - val_precision: 0.4453 - val_recall: 0.6745 - val_auc: 0.8600\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.1489 - acc: 0.9504 - precision: 0.9242 - recall: 0.9813 - auc: 0.9822 - val_loss: 0.4110 - val_acc: 0.8788 - val_precision: 0.4365 - val_recall: 0.6807 - val_auc: 0.8598\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1431 - acc: 0.9530 - precision: 0.9273 - recall: 0.9832 - auc: 0.9832 - val_loss: 0.4229 - val_acc: 0.8803 - val_precision: 0.4397 - val_recall: 0.6683 - val_auc: 0.8557\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1390 - acc: 0.9543 - precision: 0.9291 - recall: 0.9837 - auc: 0.9839 - val_loss: 0.4203 - val_acc: 0.8825 - val_precision: 0.4452 - val_recall: 0.6535 - val_auc: 0.8533\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1354 - acc: 0.9557 - precision: 0.9311 - recall: 0.9842 - auc: 0.9847 - val_loss: 0.4501 - val_acc: 0.8812 - val_precision: 0.4423 - val_recall: 0.6683 - val_auc: 0.8539\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1282 - acc: 0.9593 - precision: 0.9349 - recall: 0.9873 - auc: 0.9859 - val_loss: 0.4580 - val_acc: 0.8750 - val_precision: 0.4254 - val_recall: 0.6708 - val_auc: 0.8521\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1239 - acc: 0.9605 - precision: 0.9364 - recall: 0.9880 - auc: 0.9867 - val_loss: 0.4602 - val_acc: 0.8818 - val_precision: 0.4429 - val_recall: 0.6522 - val_auc: 0.8506\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1187 - acc: 0.9624 - precision: 0.9390 - recall: 0.9890 - auc: 0.9877 - val_loss: 0.4818 - val_acc: 0.8773 - val_precision: 0.4311 - val_recall: 0.6658 - val_auc: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x14c795550>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating a OS NN\n",
    "pca_NN = keras.Sequential()\n",
    "\n",
    "# 3 layers, double the size at each layer, and 30% dropout at each layer\n",
    "pca_NN.add(Dense(32, 'relu', input_shape=(110,)))\n",
    "pca_NN.add(Dense(64, 'relu'))\n",
    "pca_NN.add(Dense(128, 'relu'))\n",
    "# 1 output\n",
    "pca_NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "pca_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall','AUC'])\n",
    "\n",
    "pca_NN.fit(X_train_transformed, y_train_os, epochs=25, steps_per_epoch=50, validation_data=(X_test_transformed, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout in each layer and\n",
    "    # the learning rate of RMSProp optimizer.\n",
    "\n",
    "    # We define our MLP.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    model = keras.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        num_hidden = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True)\n",
    "        model.add(Dense(num_hidden, activation=\"relu\"))\n",
    "        dropout = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        metrics=[\"accuracy\", \"Recall\", \"Precision\", \"AUC\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    # Clear clutter from previous session graphs.\n",
    "    # Generate our trial model.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        X_train_os,\n",
    "        y_train_os,\n",
    "        callbacks=[optuna.integration.TFKerasPruningCallback(trial, \"val_accuracy\")],\n",
    "        validation_data=(X_test, y_test),\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return score[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:08:22,388]\u001B[0m A new study created in memory with name: no-name-2c87de1f-183a-47d3-b45d-bfc8b820a475\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 6s 3ms/step - loss: 28.6465 - accuracy: 0.6031 - recall: 0.8033 - precision: 0.5736 - auc: 0.6485 - val_loss: 1.1084 - val_accuracy: 0.3570 - val_recall: 0.9616 - val_precision: 0.1321 - val_auc: 0.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:08:29,377]\u001B[0m Trial 0 finished with value: 0.3569997549057007 and parameters: {'n_layers': 1, 'n_units_l0': 37, 'dropout_l0': 0.3067475205405741, 'learning_rate': 7.992263750104924e-05}. Best is trial 0 with value: 0.3569997549057007.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 6.1388 - accuracy: 0.5081 - recall: 0.6362 - precision: 0.5065 - auc: 0.5122 - val_loss: 0.6652 - val_accuracy: 0.8988 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:08:35,021]\u001B[0m Trial 1 finished with value: 0.8988229632377625 and parameters: {'n_layers': 1, 'n_units_l0': 37, 'dropout_l0': 0.2706902374099793, 'learning_rate': 0.014893590634633382}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 39.7141 - accuracy: 0.5918 - recall: 0.7805 - precision: 0.5667 - auc: 0.6129 - val_loss: 1.2987 - val_accuracy: 0.2894 - val_recall: 0.9604 - val_precision: 0.1209 - val_auc: 0.6091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:08:40,730]\u001B[0m Trial 2 finished with value: 0.2893814146518707 and parameters: {'n_layers': 1, 'n_units_l0': 43, 'dropout_l0': 0.42390250382754746, 'learning_rate': 5.47521899420535e-05}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 7s 2ms/step - loss: 2.1717 - accuracy: 0.5021 - recall: 0.6496 - precision: 0.5016 - auc: 0.5038 - val_loss: 1.0016 - val_accuracy: 0.8964 - val_recall: 0.0037 - val_precision: 0.1200 - val_auc: 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:08:48,145]\u001B[0m Trial 3 finished with value: 0.896443784236908 and parameters: {'n_layers': 2, 'n_units_l0': 22, 'dropout_l0': 0.3985510510211421, 'n_units_l1': 14, 'dropout_l1': 0.2037287526433547, 'learning_rate': 0.0009079982671871224}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 6s 3ms/step - loss: 1.8250 - accuracy: 0.5006 - recall: 0.9134 - precision: 0.5003 - auc: 0.5032 - val_loss: 0.6947 - val_accuracy: 0.1012 - val_recall: 1.0000 - val_precision: 0.1012 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:08:55,135]\u001B[0m Trial 4 finished with value: 0.10117705911397934 and parameters: {'n_layers': 3, 'n_units_l0': 92, 'dropout_l0': 0.25470317362216915, 'n_units_l1': 117, 'dropout_l1': 0.21640855568752967, 'n_units_l2': 9, 'dropout_l2': 0.45963107057653496, 'learning_rate': 0.00029751307225551956}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 4.6312 - accuracy: 0.6706 - recall: 0.8836 - precision: 0.6196 - auc: 0.7276 - val_loss: 0.3891 - val_accuracy: 0.8244 - val_recall: 0.7970 - val_precision: 0.3422 - val_auc: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:00,688]\u001B[0m Trial 5 finished with value: 0.8244428038597107 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'dropout_l0': 0.25755086928161247, 'learning_rate': 0.0009562156065466245}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1790/1795 [============================>.] - ETA: 0s - loss: 15.0371 - accuracy: 0.5321 - recall: 0.6904 - precision: 0.5244 - auc: 0.5383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:05,731]\u001B[0m Trial 6 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1779/1795 [============================>.] - ETA: 0s - loss: 37.6286 - accuracy: 0.6120 - recall: 0.7159 - precision: 0.5923 - auc: 0.6401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:10,622]\u001B[0m Trial 7 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 50.9304 - accuracy: 0.5028 - recall: 0.4312 - precision: 0.5033 - auc: 0.5070 - val_loss: 2.4810 - val_accuracy: 0.7670 - val_recall: 0.2314 - val_precision: 0.1310 - val_auc: 0.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:15,772]\u001B[0m Trial 8 finished with value: 0.7669671773910522 and parameters: {'n_layers': 3, 'n_units_l0': 19, 'dropout_l0': 0.31097610457769137, 'n_units_l1': 23, 'dropout_l1': 0.37153022728050294, 'n_units_l2': 48, 'dropout_l2': 0.4907202831512819, 'learning_rate': 1.579766318609225e-05}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780/1795 [============================>.] - ETA: 0s - loss: 28.9414 - accuracy: 0.5346 - recall: 0.7356 - precision: 0.5245 - auc: 0.5491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:21,253]\u001B[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 6s 3ms/step - loss: 0.7629 - accuracy: 0.5022 - recall: 0.4890 - precision: 0.5023 - auc: 0.5033 - val_loss: 0.6813 - val_accuracy: 0.8988 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:27,808]\u001B[0m Trial 10 finished with value: 0.8988229632377625 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_l0': 0.4750818299279267, 'n_units_l1': 105, 'dropout_l1': 0.49986428150910145, 'learning_rate': 0.04518581468579907}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 4s 2ms/step - loss: 1.8775 - accuracy: 0.4998 - recall: 0.5003 - precision: 0.4998 - auc: 0.5001 - val_loss: 0.6342 - val_accuracy: 0.8988 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:32,787]\u001B[0m Trial 11 finished with value: 0.8988229632377625 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'dropout_l0': 0.4967570073036629, 'n_units_l1': 118, 'dropout_l1': 0.499123815298541, 'learning_rate': 0.04744835325331595}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 0.7697 - accuracy: 0.4994 - recall: 0.5322 - precision: 0.4994 - auc: 0.4988 - val_loss: 0.6436 - val_accuracy: 0.8988 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:37,947]\u001B[0m Trial 12 finished with value: 0.8988229632377625 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_l0': 0.49139754065145147, 'n_units_l1': 43, 'dropout_l1': 0.4977136632644317, 'learning_rate': 0.03539552194347708}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1791/1795 [============================>.] - ETA: 0s - loss: 1.0278 - accuracy: 0.5019 - recall: 0.5422 - precision: 0.5017 - auc: 0.4994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:42,679]\u001B[0m Trial 13 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780/1795 [============================>.] - ETA: 0s - loss: 1.0930 - accuracy: 0.5035 - recall: 0.5781 - precision: 0.5027 - auc: 0.5020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:46,990]\u001B[0m Trial 14 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 0.7710 - accuracy: 0.5007 - recall: 0.5337 - precision: 0.5007 - auc: 0.5032 - val_loss: 0.6634 - val_accuracy: 0.8988 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:52,635]\u001B[0m Trial 15 finished with value: 0.8988229632377625 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'dropout_l0': 0.35731677382450844, 'n_units_l1': 43, 'dropout_l1': 0.42530366220779703, 'learning_rate': 0.009589540024318003}. Best is trial 1 with value: 0.8988229632377625.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 5s 2ms/step - loss: 80.3992 - accuracy: 0.5324 - recall: 0.3562 - precision: 0.5501 - auc: 0.5431 - val_loss: 0.6501 - val_accuracy: 0.8989 - val_recall: 0.0050 - val_precision: 0.5714 - val_auc: 0.5023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:09:58,526]\u001B[0m Trial 16 finished with value: 0.8989481329917908 and parameters: {'n_layers': 1, 'n_units_l0': 126, 'dropout_l0': 0.20783526359847965, 'learning_rate': 0.08557404442998885}. Best is trial 16 with value: 0.8989481329917908.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770/1795 [============================>.] - ETA: 0s - loss: 40.1522 - accuracy: 0.5199 - recall: 0.6696 - precision: 0.5155 - auc: 0.5291"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:10:03,978]\u001B[0m Trial 17 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775/1795 [============================>.] - ETA: 0s - loss: 3.6284 - accuracy: 0.7148 - recall: 0.8795 - precision: 0.6615 - auc: 0.7936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:10:10,512]\u001B[0m Trial 18 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789/1795 [============================>.] - ETA: 0s - loss: 16.1834 - accuracy: 0.5030 - recall: 0.4847 - precision: 0.5030 - auc: 0.5035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2021-12-01 13:10:15,688]\u001B[0m Trial 19 pruned. Trial was pruned at epoch 0.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  20\n",
      "  Number of pruned trials:  8\n",
      "  Number of complete trials:  12\n",
      "Best trial:\n",
      "  Value:  0.8989481329917908\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 126\n",
      "    dropout_l0: 0.20783526359847965\n",
      "    learning_rate: 0.08557404442998885\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=20)\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}