{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook Summary\n",
    "In this Notebook:\n",
    "- All columns related to ADHD are removed\n",
    "- All NaN values present in the dataset are addressed\n",
    "- A train-test split is performed on the data, and a validation set is created\n",
    "- transformed/cleaned data is saved as CSV files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# Relevant imports\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "nsch20 = pd.read_sas('../Data/nsch_2020_topical_SAS/nsch_2020_topical.sas7bdat')\n",
    "nsch19 = pd.read_sas('../Data/nsch_2019_topical_SAS/nsch_2019_topical.sas7bdat')\n",
    "nsch18 = pd.read_sas('../Data/nsch_2018_topical_SAS/nsch_2018_topical.sas7bdat')\n",
    "\n",
    "# Joining all the data into one frame, keeping ONLY the columns that are present in all frames.\n",
    "nsch = pd.concat([nsch20, nsch19, nsch18], join='inner', ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ADHD Columns\n",
    "\n",
    "Along with our target column, 'K2Q31A' there are multiple other columns that relate to ADHD that need to be removed. These columns are closely tied to ADHD so they need to be removed so the model doesn't take them into account when making predictions. Column descriptions can be found in the [EDA notebook](https://github.com/austint1121/Undiagnosed-ADHD-Identification/blob/main/Notebooks/EDA.ipynb). We will also save our target column, and remove any rows with null values in that column"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Creating list of columns to be dropped\n",
    "related_ADHD = [\n",
    "    'K2Q31A',\n",
    "    'K2Q31B',\n",
    "    'K2Q31C',\n",
    "    'K2Q31D',\n",
    "    'K4Q23',\n",
    "    'SC_K2Q10',\n",
    "    'SC_K2Q11',\n",
    "    'SC_K2Q12',\n",
    "    'ADDTREAT',\n",
    "    'SC_CSHCN',\n",
    "    'SC_K2Q22',\n",
    "    'SC_K2Q10',\n",
    "    'K4Q22_R',\n",
    "    'K6Q15',\n",
    "    'SC_K2Q20',\n",
    "    'K4Q36',\n",
    "    'TOTNONSHCN',\n",
    "    'K4Q28X04',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 102034 entries, 0 to 102739\n",
      "Columns: 411 entries, FIPSST to FWC\n",
      "dtypes: float64(407), object(4)\n",
      "memory usage: 320.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with NAN values in target column\n",
    "dropped_adhd = nsch.dropna(subset=['K2Q31A'])\n",
    "\n",
    "# Saving Target column\n",
    "target = dropped_adhd['K2Q31A']\n",
    "\n",
    "# Creating new dataframe without columns from above\n",
    "dropped_adhd = dropped_adhd.drop(columns=related_ADHD)\n",
    "\n",
    "# Confirming expected results\n",
    "dropped_adhd.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binarizing Target Values\n",
    "Currently in our target column a \"1\" means that the child has been diagnosed with ADHD and a 2 means they haven't been. This will cause problems down the road later, so I'm going to manually replace them with 0's and 1's."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0    91695\n1.0    10339\nName: K2Q31A, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary for replacement\n",
    "testing = {2: 0, 1: 1}\n",
    "\n",
    "# Preforming replacement\n",
    "target = target.replace(testing)\n",
    "\n",
    "# Visually confirming expected change\n",
    "target.value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropping Object Columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 102034 entries, 0 to 102739\n",
      "Columns: 411 entries, FIPSST to FWC\n",
      "dtypes: float64(407), object(4)\n",
      "memory usage: 320.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the column types\n",
    "dropped_adhd.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       FIPSST STRATUM         HHID FORMTYPE\n0       b'17'    b'1'  b'20000003'    b'T1'\n1       b'29'   b'2A'  b'20000004'    b'T3'\n2       b'47'    b'1'  b'20000005'    b'T1'\n3       b'28'    b'1'  b'20000014'    b'T3'\n4       b'55'    b'1'  b'20000015'    b'T3'\n...       ...     ...          ...      ...\n102735  b'33'    b'1'  b'18176000'    b'T2'\n102736  b'53'    b'1'  b'18176008'    b'T1'\n102737  b'48'   b'2A'  b'18176020'    b'T2'\n102738  b'13'   b'2A'  b'18176022'    b'T2'\n102739  b'46'    b'1'  b'18176036'    b'T1'\n\n[102034 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FIPSST</th>\n      <th>STRATUM</th>\n      <th>HHID</th>\n      <th>FORMTYPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b'17'</td>\n      <td>b'1'</td>\n      <td>b'20000003'</td>\n      <td>b'T1'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b'29'</td>\n      <td>b'2A'</td>\n      <td>b'20000004'</td>\n      <td>b'T3'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b'47'</td>\n      <td>b'1'</td>\n      <td>b'20000005'</td>\n      <td>b'T1'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b'28'</td>\n      <td>b'1'</td>\n      <td>b'20000014'</td>\n      <td>b'T3'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b'55'</td>\n      <td>b'1'</td>\n      <td>b'20000015'</td>\n      <td>b'T3'</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>102735</th>\n      <td>b'33'</td>\n      <td>b'1'</td>\n      <td>b'18176000'</td>\n      <td>b'T2'</td>\n    </tr>\n    <tr>\n      <th>102736</th>\n      <td>b'53'</td>\n      <td>b'1'</td>\n      <td>b'18176008'</td>\n      <td>b'T1'</td>\n    </tr>\n    <tr>\n      <th>102737</th>\n      <td>b'48'</td>\n      <td>b'2A'</td>\n      <td>b'18176020'</td>\n      <td>b'T2'</td>\n    </tr>\n    <tr>\n      <th>102738</th>\n      <td>b'13'</td>\n      <td>b'2A'</td>\n      <td>b'18176022'</td>\n      <td>b'T2'</td>\n    </tr>\n    <tr>\n      <th>102739</th>\n      <td>b'46'</td>\n      <td>b'1'</td>\n      <td>b'18176036'</td>\n      <td>b'T1'</td>\n    </tr>\n  </tbody>\n</table>\n<p>102034 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 422 float64 and 4 object types. Lets investigate those 4 objects\n",
    "dropped_adhd.select_dtypes('object')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**FIPSST** - State FIPS code\n",
    "**STRATUM** - Sampling Stratum\n",
    "**HHID** - Unique Household ID\n",
    "**FORMTYPE** - A proxy for age, kids are given a form base on age ranges (T1: 0-5, T2: 6-11, T3:12-17)\n",
    "\n",
    "All of these columns can be dropped as they should have an effect on whether a child has ADHD, or they are a proxy for an already present variable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 102034 entries, 0 to 102739\n",
      "Columns: 407 entries, TOTKIDS_R to FWC\n",
      "dtypes: float64(407)\n",
      "memory usage: 317.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Dropping object columns\n",
    "dropped_final = dropped_adhd.drop(columns=['FIPSST', 'STRATUM', 'HHID', 'FORMTYPE'])\n",
    "# Confirming expected column count\n",
    "dropped_final.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Test Split\n",
    "Before doing any transformations it will be necessary to perform the train test split beforehand to prevent data leakage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set is 76525 entries\n",
      "Testing set is 19131 entries\n",
      "Validation set is 6378 entries\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dropped_final, target, random_state=15, stratify=target)\n",
    "\n",
    "# Split test into a testing and final holdout/validation set\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, random_state=15, stratify=y_test)\n",
    "\n",
    "# Printing total rows in each set\n",
    "print(f'Training set is {len(X_train)} entries')\n",
    "print(f'Testing set is {len(X_test)} entries')\n",
    "print(f'Validation set is {len(X_val)} entries')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7754 kids with ADHD in the training set\n",
      "There are 1939 kids with ADHD in the testing set\n",
      "There are 646 kids with ADHD in the validation set\n"
     ]
    }
   ],
   "source": [
    "# Printing the amount of kids diagnosed with ADHD in each split\n",
    "print(f'There are {y_train.value_counts().values[1]} kids with ADHD in the training set')\n",
    "print(f'There are {y_test.value_counts().values[1]} kids with ADHD in the testing set')\n",
    "print(f'There are {y_val.value_counts().values[1]} kids with ADHD in the validation set')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Handling Missing Values\n",
    "There are multiple strategies to handling missing values, normally I would love to use Sklearns experimental [Iterative Imputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html) however, in this survey some questions are sub questions of others, and can be left blank as a result of the answer to the parent question.\n",
    "<br>\n",
    "An example of this is the \"ADDTREAT\" column we dropped earlier. This column is left blank if \"K2Q31A\" (our target) is answered \"No\". For now, I will create an imputer but not use it yet, as it would take a large amount of time for it to run on the large dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Simple Imputer filling values with something that vill obviously be a nan value, in this case, 999\n",
    "SI_imputer = SimpleImputer(strategy='constant', fill_value=999)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   TOTKIDS_R  TENURE  HHLANGUAGE  SC_AGE_YEARS  SC_SEX  K2Q35A_1_YEARS  \\\n0        2.0     1.0         1.0           7.0     1.0           999.0   \n1        2.0     1.0         1.0           9.0     1.0           999.0   \n2        3.0     1.0         1.0           6.0     2.0           999.0   \n3        1.0     1.0         1.0           6.0     2.0           999.0   \n4        1.0     2.0         3.0           3.0     2.0           999.0   \n\n   MOMAGE  K6Q41R_STILL  K6Q42R_NEVER  K6Q43R_NEVER  ...  A1_GRADE_IF  \\\n0    35.0         999.0         999.0         999.0  ...          0.0   \n1    28.0         999.0         999.0         999.0  ...          0.0   \n2    31.0         999.0         999.0         999.0  ...          0.0   \n3    34.0         999.0         999.0         999.0  ...          0.0   \n4    30.0           2.0           1.0           1.0  ...          0.0   \n\n   BMICLASS  HHCOUNT_IF  FPL_I1  FPL_I2  FPL_I3  FPL_I4  FPL_I5  FPL_I6  \\\n0     999.0         0.0   400.0   400.0   400.0   400.0   400.0   400.0   \n1     999.0         0.0   400.0   400.0   400.0   400.0   400.0   400.0   \n2     999.0         0.0   176.0   220.0   153.0   175.0   400.0   400.0   \n3     999.0         0.0   400.0   400.0   400.0   400.0   400.0   400.0   \n4     999.0         0.0   104.0   104.0   104.0   104.0   104.0   104.0   \n\n           FWC  \n0   946.327377  \n1  2283.583410  \n2   258.317200  \n3  2549.241201  \n4    93.141525  \n\n[5 rows x 407 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TOTKIDS_R</th>\n      <th>TENURE</th>\n      <th>HHLANGUAGE</th>\n      <th>SC_AGE_YEARS</th>\n      <th>SC_SEX</th>\n      <th>K2Q35A_1_YEARS</th>\n      <th>MOMAGE</th>\n      <th>K6Q41R_STILL</th>\n      <th>K6Q42R_NEVER</th>\n      <th>K6Q43R_NEVER</th>\n      <th>...</th>\n      <th>A1_GRADE_IF</th>\n      <th>BMICLASS</th>\n      <th>HHCOUNT_IF</th>\n      <th>FPL_I1</th>\n      <th>FPL_I2</th>\n      <th>FPL_I3</th>\n      <th>FPL_I4</th>\n      <th>FPL_I5</th>\n      <th>FPL_I6</th>\n      <th>FWC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>999.0</td>\n      <td>35.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>999.0</td>\n      <td>0.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>946.327377</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>999.0</td>\n      <td>28.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>999.0</td>\n      <td>0.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>2283.583410</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>999.0</td>\n      <td>31.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>999.0</td>\n      <td>0.0</td>\n      <td>176.0</td>\n      <td>220.0</td>\n      <td>153.0</td>\n      <td>175.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>258.317200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>999.0</td>\n      <td>34.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>999.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>999.0</td>\n      <td>0.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>400.0</td>\n      <td>2549.241201</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>999.0</td>\n      <td>30.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>999.0</td>\n      <td>0.0</td>\n      <td>104.0</td>\n      <td>104.0</td>\n      <td>104.0</td>\n      <td>104.0</td>\n      <td>104.0</td>\n      <td>104.0</td>\n      <td>93.141525</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 407 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the imputer to training data / transforming the training data\n",
    "transformed_X_train = SI_imputer.fit_transform(X_train, y_train)\n",
    "\n",
    "# Creating a dataframe and re-adding the column names to the data\n",
    "transformed_X_train = pd.DataFrame(transformed_X_train, columns=X_train.columns)\n",
    "\n",
    "# Visually confirming transformation\n",
    "transformed_X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Transforming test and validation set\n",
    "transformed_X_test = SI_imputer.transform(X_test)\n",
    "\n",
    "# Creating a dataframe and re-adding the column names to the data\n",
    "transformed_X_test= pd.DataFrame(transformed_X_test, columns=X_test.columns)\n",
    "\n",
    "# Transforming Validation set\n",
    "transformed_X_val = SI_imputer.transform(X_val)\n",
    "\n",
    "# Creating a dataframe and re-adding the column names to the data\n",
    "transformed_X_val= pd.DataFrame(transformed_X_val, columns=X_val.columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Saving the transformed dataframes\n",
    "\n",
    "# Training Data\n",
    "transformed_X_train.to_csv('../Data/train/X_train_combo.csv')\n",
    "y_train.to_csv('../Data/train/y_train_combo.csv')\n",
    "\n",
    "# Testing Data\n",
    "transformed_X_test.to_csv('../Data/test/X_test_combo.csv')\n",
    "y_test.to_csv('../Data/test/y_test_combo.csv')\n",
    "\n",
    "# Validation Data\n",
    "transformed_X_val.to_csv('../Data/val/X_val_combo.csv')\n",
    "y_val.to_csv('../Data/val/y_val_combo.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From this point forward, any more cleaning would be model specific. I could also clean the data more to improve the overall quality, but I think this will be a good \"baseline\" starting point for the modeling process. The next step is to begin the [modeling proccess](Modeling/First_Simple_Models.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}