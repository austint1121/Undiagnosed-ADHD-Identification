{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FSM Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- In this Notebook I will be creating 3 simple models with:\n",
    "    - Sklearn's Base Decision Tree\n",
    "    - Catboost\n",
    "    - Keras\n",
    "\n",
    "I'll evaluate on all of these FSMs and decide how to move forward, and how to split my time between these model types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "# Import statements\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from keras.layers import Dense\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Importing metrics function from functions.py\n",
    "from functions import metrics as custom_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load in cleaned data from last time.\n",
    "\n",
    "# Training Data\n",
    "X_train = pd.read_csv('../../Data/train/X_train_combo.csv', index_col=0)\n",
    "y_train = pd.read_csv('../../Data/train/y_train_combo.csv', index_col=0)\n",
    "\n",
    "# Testing Data\n",
    "X_test = pd.read_csv('../../Data/test/X_test_combo.csv', index_col=0)\n",
    "y_test = pd.read_csv('../../Data/test/y_test_combo.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeless Baseline\n",
    "A modeless baseline is how accurate we would be if we guessed the majority class of our target variable. In this case, how accurate would we be if we guessed that the child in question did not have ADHD, for every child. This will be same for every split since we set the stratify parameter to true when we performed the TTS. It will be important to keep this metric in mind when modeling, to see when the model is just guessing the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "K2Q31A\n0.0       0.898907\n1.0       0.101093\ndtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we said that each child in the set did not have ADHD, we would be 90% accurate\n"
     ]
    }
   ],
   "source": [
    "# Getting % of each class and assigning to variables\n",
    "no_adhd, adhd = y_train.value_counts(normalize=True)\n",
    "\n",
    "# Printing modeless accuracy\n",
    "print(f'If we said that each child in the set did not have ADHD, we would be {no_adhd*100:.0f}% accurate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM - Sklearn Decision Tree\n",
    "\n",
    "To start let's create the simplest model possible, to use as a baseline for future models. I'll use a Decision Tree model from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1: 1.00\n",
      "ROC AUC: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1': 1.0, 'ROCAUC': 1.0}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating Tree\n",
    "FSM_DT = DecisionTreeClassifier()\n",
    "\n",
    "# Fitting Model\n",
    "FSM_DT.fit(X_train, y_train)\n",
    "\n",
    "# Score on the training data.\n",
    "custom_score(X_train, y_train, FSM_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wow! A perfect Score!\n",
    "I guess we can go home, we did it, we solved ADHD\n",
    "\n",
    "Just kidding, lets check the score on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Results\n",
      "Accuracy: 0.90\n",
      "Precision: 0.48\n",
      "Recall: 0.51\n",
      "F1: 0.50\n",
      "ROC AUC: 0.73\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Accuracy': 0.8950663661407463,\n 'Precision': 0.48259860788863107,\n 'Recall': 0.5148514851485149,\n 'F1': 0.49820359281437127,\n 'ROCAUC': 0.7263585929504067}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "FSM_DT_preds = FSM_DT.predict(X_test)\n",
    "\n",
    "# Print metrics\n",
    "custom_score(X_test, y_test, FSM_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.0    7124\n1.0     862\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the predictions to ensure that the model isn't guessing one class\n",
    "pd.Series(FSM_DT_preds).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis\n",
    "The model is, obviously, overfit to the training data, and on the testing data it may as well be guessing. This is expected of an un-pruned DT model though.\n",
    "I'd like to try a few different kinds of first models, so before iterating on this one let's create a few more FSMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FSM - CatBoost\n",
    "Catboost is not an Sklearn library, but is known for doing very well on categorical data like the one from this survey. Let's give it a shot and see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "model = CatBoostClassifier(\n",
    "    # Adding Accuracy as a metric\n",
    "    custom_loss=[metrics.Accuracy()],\n",
    "    random_seed=15,\n",
    "    logging_level='Silent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaf6d95ff4364da09ae1ee396ae6e8ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting the model to training data\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    # Using X/y test as eval set\n",
    "    eval_set=(X_test, y_test),\n",
    "    # Plot the learning of the model\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f1e48d346b4482195de68169d635662"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updating model params with Logloss function\n",
    "cv_params = model.get_params()\n",
    "cv_params.update({\n",
    "    'loss_function': metrics.Logloss()\n",
    "})\n",
    "# Pooling data and cross validating\n",
    "cv_data = cv(\n",
    "    Pool(X_train, y_train),\n",
    "    cv_params,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Model Results\n",
      "Accuracy: 0.97\n",
      "Precision: 0.95\n",
      "Recall: 0.75\n",
      "F1: 0.83\n",
      "ROC AUC: 0.87\n",
      "\t\n",
      "Testing Scores\n",
      "Model Results\n",
      "Accuracy: 0.94\n",
      "Precision: 0.74\n",
      "Recall: 0.56\n",
      "F1: 0.64\n",
      "ROC AUC: 0.77\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Accuracy': 0.9356373653894315,\n 'Precision': 0.7401960784313726,\n 'Recall': 0.5606435643564357,\n 'F1': 0.6380281690140845,\n 'ROCAUC': 0.769246273680029}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing training and testing scores.\n",
    "print(\"Training Scores\")\n",
    "custom_score(X_train, y_train, model)\n",
    "print('\\t')\n",
    "print('Testing Scores')\n",
    "custom_score(X_test, y_test, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "Catboost has done quite well for a baseline model! There is, again, some bad overfitting occuring here. But the scores are still better then the base decision tree; precision, recall, and roc/auc have all vastly improved compared to the base decision tree. Lets move on to something totally different, a neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FSM - Keras NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Instantiating a NN\n",
    "FSM_NN = keras.Sequential()\n",
    "\n",
    "# Starting small with 30 neurons\n",
    "FSM_NN.add(Dense(30, 'relu', input_shape=(422,)))\n",
    "\n",
    "# 1 output\n",
    "FSM_NN.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "# Compiling model with accuracy, precision, and recall metrics. Using \"Adam\" as an optimizer\n",
    "FSM_NN.compile('adam', 'binary_crossentropy', metrics=['acc', 'Precision', 'Recall'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 10ms/step - loss: 19.1255 - acc: 0.8776 - precision: 0.3934 - recall: 0.3880 - val_loss: 10.8361 - val_acc: 0.8785 - val_precision: 0.4104 - val_recall: 0.4592\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8.8990 - acc: 0.8916 - precision: 0.4641 - recall: 0.4710 - val_loss: 7.2743 - val_acc: 0.9021 - val_precision: 0.5179 - val_recall: 0.4666\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 6.1495 - acc: 0.8934 - precision: 0.4726 - recall: 0.4729 - val_loss: 6.9907 - val_acc: 0.9125 - val_precision: 0.6301 - val_recall: 0.3267\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 5.7175 - acc: 0.8974 - precision: 0.4924 - recall: 0.4847 - val_loss: 5.1436 - val_acc: 0.8651 - val_precision: 0.3955 - val_recall: 0.6300\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 7.7154 - acc: 0.8841 - precision: 0.4257 - recall: 0.4203 - val_loss: 7.3098 - val_acc: 0.9152 - val_precision: 0.6058 - val_recall: 0.4641\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.9446 - acc: 0.9032 - precision: 0.5208 - recall: 0.5352 - val_loss: 3.5360 - val_acc: 0.9091 - val_precision: 0.5574 - val_recall: 0.4926\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 7.0948 - acc: 0.8886 - precision: 0.4480 - recall: 0.4404 - val_loss: 4.9225 - val_acc: 0.9048 - val_precision: 0.5284 - val_recall: 0.5520\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.3295 - acc: 0.9034 - precision: 0.5222 - recall: 0.5212 - val_loss: 3.2699 - val_acc: 0.9095 - val_precision: 0.5598 - val_recall: 0.4926\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 2.5923 - acc: 0.9018 - precision: 0.5139 - recall: 0.5221 - val_loss: 3.2979 - val_acc: 0.9106 - val_precision: 0.6588 - val_recall: 0.2413\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 3.8962 - acc: 0.8881 - precision: 0.4464 - recall: 0.4460 - val_loss: 9.6905 - val_acc: 0.9025 - val_precision: 0.7302 - val_recall: 0.0569\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1471a6a30>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model on X_train and binarized labels\n",
    "FSM_NN.fit(X_train, y_train, epochs=10, steps_per_epoch=100, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 9.6905 - acc: 0.9025 - precision: 0.7302 - recall: 0.0569\n"
     ]
    }
   ],
   "source": [
    "# Getting stats for test data\n",
    "NN_loss, NN_acc, NN_prec, NN_recall = FSM_NN.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.90 \n",
      " Test Precision: 0.73 \n",
      " Test Recall: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Neatly printing evaluation results\n",
    "print(f'Test Accuracy: {NN_acc:.2f} \\n Test Precision: {NN_prec:.2f} \\n Test Recall: {NN_recall:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis\n",
    "The neural network has an impressively bad recall score at 6%. I think that this poor neural network could use some more neurons, but it is trying its best with what it has.\n",
    "\n",
    "# Conclusion\n",
    "All baseline models had high accuracy due to the class imbalance, but had poor recall/precision scores. The neural network by far having the worst recall score at 6%, and the base decision tree having the worst precision at around 0.48.  Moving forward this is what I'm planning:\n",
    "\n",
    "1. Spend a very small amount of time on the base decision tree, perhaps iterate only once or twice.\n",
    "\n",
    "2. Catboost will be the way to go here, I'll spend the most time iterating off of this model.\n",
    "\n",
    "3. Spend a moderate amount of time on the neural network, and see if it will do better then Catboost.\n",
    "\n",
    "I think that Catboost has the most potential here, and I'm confident that it will do better then a base decision tree ever could. I think it will be interesting to see what happens with the Neural network. I'm wondering if it will be able to do much better then Catboost, and if it can, will it be worth the tradeoff of training time and processing power?\n",
    "\n",
    "Let's start with a [decision tree](Modeling-Decision_Tree.ipynb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}